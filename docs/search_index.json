[["index.html", "Bevezetés a biostatisztikába 1 . fejezet Elszó", " Bevezetés a biostatisztikába Ferenci Tamás 2021-02-26 1 . fejezet Elszó Elszó. "],["a-statisztika-alapjai.html", "2 . fejezet A statisztika alapjai 2.1 A statisztika alapfogalmai és ágai 2.2 Változók és mérési skálák 2.3 A biostatisztika kapcsolódó tudományai és elhatárolása 2.4 A biostatisztika számítástechnikai háttere 2.5 Futó példa", " 2 . fejezet A statisztika alapjai Alapfogalmak. 2.1 A statisztika alapfogalmai és ágai Azt a halmazt, melyre a statisztikai eszközökkel megvizsgálandó kérdésünk vonatkozik (cél)populációnak, vagy sokaságnak szokás nevezni. A sokaság elemeit szokás megfigyelési egységnek is nevezni. Ha azt kérdezzük, hogy ,,Mennyi egy adott kurzus hallgatóinak átlagos testtömege?, akkor a sokaság az adott kurzus hallgatóiból álló halmaz; a megfigyelési egységek az egyes hallgatók. Azt a szempontot, amely szerint a sokaság elemeit vizsgálat alá vonjuk, ismérvnek, vagy más szóval változónak hívjuk. Az elbbi példa esetében a változó a testtömeg; más esetekben persze több változót is használunk. Azt a lépést, amikor adott változó értékét meghatározzák egy adott sokasági elemre, általában megfigyelésnek nevezik a statisztikában. Nagyon sokszor nem tudunk a sokaság valamennyi egyedérl információt szerezni (azaz: nem tudjuk mindegyiket megfigyelni). Ilyenkor a sokaság azon részhalmazát, amelyet meg tudunk figyelni (tehát amelyrl információnk van), mintának nevezzük, és ezt a helyzetet magát mintavételi helyzetnek hívjuk. Ennek egyrészt technikai okai lehetnek: sok esetben a sokaság valamennyi egységérl való adatgyjtés (az ún. teljes kör megfigyelés) technikai okok miatt nehézkes vagy egyenesen lehetetlen (túl költséges, túl bonyolult a megszervezése, túl idigényes stb.) A biostatisztikában azonban ennél is fontosabb egy másik ok: az, hogy sok kérdés nem egy kézzelfogható, véges nagyságú sokaságra (mint egy adott kurzus hallgatói), hanem egy ún. fiktív sokaságra vonatkoznak. A kurzus hallgatóit fel lehet sorolni, felírhatjuk a neveiket egymás alá egy lapra. Egy ország lakosainál ugyan ez nehezebb a gyakorlatban, de elvileg minden további nélkül megtehet. De vessük ezt össze azzal a kérdéssel, hogy egy új vérnyomáscsökkent gyógyszer-jelölt valóban csökkenti-e a vérnyomást  mi itt a sokaság? Itt valami alapvet különbség van: ennek a sokaságnak az elemeit nem tudjuk felsorolni egy lapra! Soha nem mondhatjuk azt, hogy itt a névsor, konkrétan ket kell gyógyítania a gyógyszernek. E kérdés nem emberek egy konkrét, összeszedhet csoportjára vonatkozik, hanem egy képzeletbeli, megfoghatóan nem létez, absztrakt csoportra (,,aki megfelel a gyógyszer alkalmazási feltételeinek). Ez nem egy konkrét sokaság, hanem egy fiktív csoport; sokszor hasznos ha úgy gondolunk rá, mintha ebben végtelen sok elem lenne. Ebbl az is következik, hogy akármennyi embert is vizsgálunk meg ebbl a sokaságból, az szükségképp csak része lesz annak, azaz szükségképp csak mintát fog jelenteni a sokaságból. Ilyenkor tehát mindenképp mintavételi helyzettel lesz dolgunk. Mivel ez a helyzet tipikus a biostatisztikában, így máris érthet, hogy miért mondtuk, hogy a mintavételi helyzetnek  illetve kezelésének  kiemelt jelentsége van a biostatisztikában. A statisztika azon ágát, mely sokaságról szerzett adatokkal foglalkozik, vagy mintabeliekkel de úgy, hogy elhanyagolja, hogy csak mintáról van szó (mintha a minta lenne a sokaság) deskriptív (vagy leíró) statisztikának nevezik; errl késbb bvebben lesz szó (3. fejezet). Ide tartoznak olyan kérdések, mint az információtömörítés, lényegkiemelés, adatvizualizáció. A statisztika azon ága, mely figyelembe veszi a mintavételi helyzetet, azaz mintabeli adatokkal foglalkozik, de úgy, hogy szem eltt tartja, hogy a kérdések valójában a sokaságra irányulnak, induktív (vagy következtet) statisztikának nevezik, szintén részletesen lesz róla szó késbb (4 . fejezet). 2.2 Változók és mérési skálák Az elbbi pontban kissé nagyvonalúan csak annyit írtunk, hogy a változó (vagy ismérv) az a szempont, ami alapján a megfigyelési egységeket vizsgálat alá vonjuk. (Természetesen több ilyen is szerepelhet egy vizsgálatban.) Ez meglehetsen kézenfekv akkor, ha mondjuk az emberek testtömege a vizsgálati szempont  ekkor mondhatjuk egyszeren, hogy lemérjük ket alkalmas módszerrel, és az e tulajdonságot leíró ,,testtömeg változó legyen a lemért tömeg mondjuk kilogrammban kifejezett értéke. Más esetekben azonban közel nem ilyen egyértelm a változók megválasztásának a kérdése. A statisztika alapveten számszer információk feldolgozásával foglalkozó tudomány, így ahhoz, hogy egy szempontot statisztikai úton tudjunk vizsgálni, elbb számszeren mérhetvé kell tenni. Ez természetesen olyan információkkal is végrehajtható, melyek eredetileg nem számszerek. Ezt nevezzük operacionalizálásnak. Néha ez valóban szinte triviális feladat (a testtömeget mérjük az adott módon lemért és kilogrammban kifejezett testtömeggel), máskor viszont egyáltalán nem az. Gondoljunk arra, hogy hogyan lehet számszeren mérhetvé tenni egy olyan jellemzt, mint hogy milyen súlyos egy alany depressziója  szinte külön tudományág, hogy ehhez milyen kérdívek, egyéb vizsgálatok kellenek, mellyel ,,lemérhet ez. A változók kapcsán a másik probléma, hogy egy sor tulajdonság nem mérhet közvetlenül  akár technikai akadályok miatt, akár az operacionalizálás nehézségei miatt. Ez esetben gyakran kényszerülünk arra, hogy az eredetileg megcélzott változó helyett más, immár mérhet, és az eredetivel  lehetleg minél szorosabb  kapcsolatban lév változót vagy változókat mérjünk le. Az ilyen célból használt változót nevezzük proxy változónak. Például komoly gondban lennénk, ha az alany szocioökonómiai státuszát kéne lemérnünk egyetlen változóval  ezt ilyen formában aligha tehetjük meg, így a gyakorlatban proxykat próbálnánk hozzá keresni, például iskolai végzettséget mérnénk, jövedelmet, munkahelyi beosztást stb. A következ kérdéskör, amirl a változók kapcsán beszélni kell, az a mérési skála fogalma. Mivel a statisztika végeredményben számszer információkat dolgoz fel, így a változóinkat is tipikusan számokkal fogjuk leírni. Észre kell azonban venni, hogy vannak jellemzi a változóknak, amik önmagukban e számokból nem olvashatóak ki. Példának okáért tekintsük azt az adatot, hogy mi az alany szemszíne, és azt, hogy mennyi a CRP-je (ez egy laboreredmény). Tételezzük most fel, hogy a szemszínt úgy számszersítettük, hogy a barnához 1-et, a feketéhez 2-t, az egyébhez 3-at rendelünk; a CRP-nél pedig a koncentrációja számértékét adjuk meg mg/l-ben. Mármost ekkor mindkét adat (a szemszín és a CRP) is lehet történetesen 1, 2 és 3 érték  ám ettl még hatalmas különbség van köztük: a CRP-nél van értelme átlagról beszélni, ,,átlagos szemszínrl nyilván nincs. E mögött az húzódik meg, hogy a CRP-k számértékeit van értelme összeadni egymással, a szemszínek számértékeit nem. Tehát: az, hogy milyen mveletek végezhetek el az adott változóval, nem olvasható ki a változó által felvett értékekbl. Ezeket a különbségeket a mérési skála fogalma ragadja meg, mely azt írja le, hogy hogyan viselkednek, viselkedhetnek az adataink. A leghíresebb Stanley Smith Stevens mérési skála modellje, mely négy lépcsfokot különböztet meg. (Azért is beszélünk lépcsfokokról, mert ez egy egymásra épül, folyamatosan bvül felosztás: a késbbi, magasabb skálák bírnak az összes többi korábbi, alacsonyabb skála tulajdonságaival, és még persze valamilyen többlettel is.) Stevens skálái a következek: Névleges (nominális) skála Ilyen skálán mért adatok esetén az adat számértékének valójában nincs semmi jelentsége, kizárólag az számít, hogy a számérték ugyanaz-e két alanynál vagy sem: ha ugyanaz, akkor a változójuk is ugyanolyan érték, ha nem akkor nem  de ennél többet nem mondhatunk! Erre jó példa a beteg lakóhelye megye szerint; 1-tl 20-ig kódolva. Ha az egyik betegnél ez 3, a másiknál 6, akkor kizárólag annyit mondhatunk, hogy különböz megyében laknak, semmi többet. Olyan kijelentéseknek, hogy a második ,,hárommal nagyobb megyében, ,,kétszer akkora megyében, vagy akár csak annak, hogy ,,nagyobb megyében lakik nyilvánvalóan nincs értelmük. További tipikus példa nominális ismérvre a beteg neme, rassza, szemszíne stb. Sorrendi (ordinális) skála Ilyen skála esetében már valamennyi jelentsége van a számértékeknek: számít ugyanis, hogy melyik  ám ezen kívül semmi más. Ezzel tehát a lehetséges kimeneteket sorba rendeztük (innen a skála neve), ám egyebet nem mondhatunk. Tipikusan ide tartozik a különféle betegségek staging adata. Ha ez egyik beteg I, a másik II stádiumban van, akkor mondhatjuk azt, hogy ez utóbbi állapota súlyosabb (figyelem, ha ez nominális skálán mért ismérv lenne, akkor már ennyit sem mondhatnánk, csak annyit, hogy a súlyosság!), ám olyan kijelentéseknek, hogy ,,eggyel súlyosabb, vagy ,,kétszer olyan súlyos állapotban van, nincs értelme. Vegyük észre, hogy ez valóban tartalmazza a nominális skála jellemzit (hiszen ha a kimenetek sorbarendezhetek, akkor természetesen meg is különböztethetek), azaz tényleg kibvítése annak. Valódi skálán mért ismérvek Ide tartoznak azok az ismérvek, amelyek kimeneteivel már egyéb mveletek (nem csak az összehasonlítás és a sorbarendezés) is értelmezettek. Például ha egy beteg CRP-je 1 mg/l, egy másiké 2 mg/l, akkor mondhatjuk, hogy a kett különbözik (nominális tulajdonság), mondhatjuk, hogy az utóbbi nagyobb (ordinális tulajdonság), de nyugodtan tehetünk olyan kijelentést is, hogy az utóbbi ,,eggyel nagyobb, vagy hogy ,,kétszer akkora mint az elbbi! Ezek a skálán mért ismérvek, ide tartozik például a legtöbb laboreredmény. A statisztikai irodalomban ezen a kategórián belül két további csoportot szokás megkülönböztetni: a különbségi  vagy intervallum  skálán mért ismérveket, és az arányskálán mért ismérveket. Az eltérés a kett között, hogy az elzben csak az összeadás, míg az utóbbiban az összeadás a szorzás is értelmezett. Például a CRP arányskálán mért, hiszen két érték vonatkozásában beszélhetünk arról, hogy az egyik mennyivel több, illetve hányszorosa a másiknak. A beteg testhmérsékleténél, ha azt Celsius-fokban mérjük, már nem ez a helyzet! Annak van értelme, hogy az egyik beteg maghmérséklete 5 \\(^\\circ\\)C-kal több, de olyat nem mondhatunk, hogy 10%-kal magasabb. Megjegyezzük, hogy az els két skálán mért változót nagyon gyakran minségi (vagy kvalitatív) változónak nevezik közös néven, míg a valódi skálán mért változókat sokszor mennyiségi (vagy kvantitatív) változónak hívják. Itt érdemes megemlíteni, hogy a változókat csoportosíthatjuk aszerint is, hogy hány lehetséges kimenetet vehetnek fel. Ha véges sokat vagy legfeljebb megszámlálhatóan végtelen sokat, akkor diszkrét változóról beszélünk, különben folytonosról. Folytonos változóra tipikus példa az olyan változó, melynek értékei a valós számok közül, vagy a valós számok valamilyen intervallumából (pl. pozitív valós számok) kerülnek ki. Természetesen a gyakorlatban a korlátos mérési pontosság miatt elvileg minden változó diszkrét, de ha nagyon nagy a lehetséges kimenetek száma, és ezek egymáshoz srn helyezkednek el, akkor általában nyugodtan alkalmazható a folytonos közelítés. Nagyon sokszor a diszkrét változó fogalmat azonosítják a minségi, a folytonosat pedig a mennyiségi változóval. Tisztán elméleti szempontból ez nem helyes (hiszen két különböz szempontról van szó), bár tény, hogy a legtöbb esetben valóban fennállnak ezek a megfeleltetések. Egy nevezetes kivétel ez alól a különféle darabszámokat, események számát stb. tartalmazó adatok, melyek a 0, 1, 2, 3 stb. értékeket vehetik fel (tehát diszkrétek), mégis skálán mértek, st, azon belül is arányskálán (tehát pont hogy a legmagasabb mérési skálán), hiszen általában van értelme nem csak különbségükrl, de akár a hányadosukról is beszélni. 2.3 A biostatisztika kapcsolódó tudományai és elhatárolása A biostatisztika az alkalmazott statisztika egyik ága, hasonlóan a pszichometriához, agrometriához stb. Látni kell, hogy a statisztika többé-kevésbé egységes tudomány, így végs soron hasonló módszereket alkalmaz az összes felsorolt ág, különbség inkább a részletekben (partikuláris problémákhoz testreszabott vagy kifejlesztett módszerek) és a az eljárások prezentációjában van. Mint minden alkalmazott ágnak, a biostatisztikának is a statisztika, matematikai statisztika adja az alapját. Az e fejezetben bemutatott módszerek jó részéhez ugyan nincs szükség mélyebb matematikai statisztikai ismeretekre, de a manapság kifejlesztett új módszerek egyre komolyabb matematikai eszköztárat használnak. A matematikai statisztika a matematika több ágára is épít, de ezek közül természetesen a valószínségszámítás a kiemelkeden legfontosabb. (Ezt több más terület is kiegészíti természetesen, például a lineáris algebra.) Nem túlzás azt mondani, hogy a valószínségszámítás a statisztika mögötti ,,alaptudomány, melynek alapos ismerete elengedhetetlen a matematikai statisztika magas szint mveléséhez. Mostani jegyzetünkben azonban egyedül az induktív statisztikai rész fog valószínségszámítási alapismereteket feltételezni, a többi rész minden speciális matematikai ismeret nélkül is követhet lesz. A valószínségszámításon, matematikai statisztikán kívül természetesen orvosi ismeretekre is szükség van a biostatisztika mveléséhez. Ha nem is feltétlenül létkérdés, de a biostatisztikus munkáját megkönnyíti, ha legalább érti az orvosok szóhasználatát, valamint tisztában van az emberi test mködésének élettani és a betegségek kórélettani alapjaival. Ezt a szakaszt azzal zárjuk, hogy kísérletet teszünk a biostatisztika elhatárolására két olyan területtl, amellyel gyakran keveredik a fogalma. Az egyik a bioinformatika: ez a manapság rendkívül népszer terület azonban inkább számítástechnikai, algoritmikus kérdésekkel foglalkozik (melyekkel nagy orvosbiológiai adatbázisokon is hatékonyan végezhetek bizonyos mveletek, megválaszolhatóvá válnak bizonyos orvosilag releváns kérdések). A másik a biomatematika, ez alatt azonban inkább olyan területet értünk, mely jellemzen nem statisztikai, hanem más matematikai (elssorban analízisbeli) eszközöket, például differenciálegyenleteket használ, és a modellek adatokból történ becslése csak másodlagos kérdés. 2.4 A biostatisztika számítástechnikai háttere Modern biostatisztika szinte elképzelhetetlen számítógépek, számítástechnikai támogatás nélkül. Ennek legalább három konkrét aspektusa van. Elször is, a leginkább ,,mechanikus támogatás, amit a gépek adhatnak, hogy a szokásos számítási mveleteket (például egy átlag meghatározása vagy egy statisztikai próba kiszámítása) végrehajtják helyettünk. Bár sok statisztika kurzuson még ma is megtanítják a hallgatókat a kézi számításra (elssorban azért, hogy jobban rögzüljenek a számítások részletei is), valójában már minden gyakorlati alkalmazásban számítógépek végzik a mechanikus kalkulációkat, érthet okokból kifolyólag. A számítógépek ennél kicsit általánosabb módon is tudják támogatni a statisztikus munkáját. Azáltal, hogy segítik a nagy adatbázisok kezelését (szrés, rendezés, keresés stb.), az adattranszformációkat (változók átkódolása, függvény szerint transzformálása stb.), lehetvé teszik, hogy könnyen kiszámoljunk mutatókat, vizualizáljunk adatokat és így tovább, a hatékonyabb, kreatívabb munkavégzést is segítik. (Részint azáltal, hogy csökkentik vagy szinte megszüntetik a rutinfeladatok idigényét, és így segítik, hogy a statisztikus a lényegre tudjon koncentrálni, részint azáltal, hogy számítógépek nélkül nem, vagy csak nagyon nehezen kivitelezhet segítségeket  pl. háromdimenziós ábrák  is tudnak adni a helyzet jobb megértéséhez.) Végül pedig, vannak bizonyos módszerek, melyek nem csak nehézkesek lennének, de egyenesen elképzelhetetlenek számítástechnikai támogatás nélkül. Ezek az ún. számításintenzív módszerek (például az újramintavételezésen alapuló eljárások, a különféle algoritmikus modellek) mind rendkívüli számításigénnyel bírnak, így lényegében a számítógépekkel egyidsek, hiszen a nélkül kifejlesztésük, és különösen az érdemi használatuk nem volt elképzelhet. Zárásként nagyon rövid ismertetkkel megemlítjük a talán legfontosabb programokat, melyeket a (bio)statisztikusok használnak: * SAS A SAS egy igen komplex, nagyméret és drága programcsomag. Legfbb elnye, hogy jól standardizált, bejáratott, és a gyógyszeriparban  épp emiatt  elszeretettel alkalmazzák. * SPSS Az egy általános célú statisztikai programcsomag (eredetileg szociológusoknak fejlesztették ki), funkcionalitása számos  egyenként megvásárolható  modullal állítható be a kívánt szintre. Grafikus kezelfelülete rendkívül egyszer és kényelmes (ráadásul nagyon sokan eleve ezt szokták meg), mellyel a beépített funkciók néhány kattintással végrehajthatóak. Cserében a bonyolultabb statisztikai problémák megoldása  noha van saját szkript-nyelve  nagyon nehézkes lehet. Összességében véve az alap dolgokat könny megcsinálni  a komplexebbeket viszont nagyon nehéz. Didaktikai hibái, gyatra adatvizualizációs lehetségei, korlátozott bvíthetsége miatt nem ajánlható a használata. * R Az a klasszikus ,,akadémiai programcsomag. Alapváltozatában még csak érdemi grafikus felület sincs hozzá, minden utasítást parancsként kell beírnunk; cserébe hihetetlen mennyiség kiegészít érhet el hozzá a legkülönfélébb alkalmazásokhoz, a legkönnyebbl a legbonyolultabbig, továbbá egy sor szakterülethez célirányosan is. (2018 elején több mint 13 ezer csomag érhet el, nem ritka, hogy napi 5-10 új jelenik meg!) Egy sor újonnan kifejlesztett statisztikai módszert elsként alatt implementálnak. Összességében elmondható, hogy itt az alap dolgokat sem könny megcsinálni  a komplexebbeket cserébe viszont lehet. Az ingyenes és nyílt forráskódú, a címrl indulva tölthet le. Használatához feltétlenül ajánlott az (szintén ingyenes és nyílt forráskódú) integrált fejlesztkörnyezet () alkalmazása. E kiegészít csomagokkal az R ereje hatalmas: rendkívül komplex feladat is végre hajthatóak egysoros hívásokkal (néha szó szerint). 2.5 Futó példa A jegyzet hátralev részében szerepl példák didaktikai okokból mind ugyanarra az adatbázisra vonatkoznak; ebben a szakaszban ezt mutatjuk be. Az adatbázis egy klasszikus demonstrációs adatbázis, általánosan használt neve Low Infant Birth Weight (LOWBWT vagy BIRTHWT); a Baystate Medical Center (Springfield, Massachusetts, Egyesült Államok) kórházban végrehajtott kutatásból (1986) származik. A kutatás célja annak vizsgálata volt, hogy milyen tényezk befolyásolják, hogy egy világra jöv újszülött kis születési tömeg lesz-e. Szemléltetésként az adatbázis els néhány megfigyelési egysége (az adatbázis megtalálható az statisztikai környezet nev könyvtárában néven): data(birthwt, package = &quot;MASS&quot;) head(birthwt, 10) ## low age lwt race smoke ptl ht ui ftv bwt ## 85 0 19 182 2 0 0 0 1 0 2523 ## 86 0 33 155 3 0 0 0 0 3 2551 ## 87 0 20 105 1 1 0 0 0 1 2557 ## 88 0 21 108 1 1 0 0 1 2 2594 ## 89 0 18 107 1 1 0 0 1 0 2600 ## 91 0 21 124 3 0 0 0 0 0 2622 ## 92 0 22 118 1 0 0 0 0 1 2637 ## 93 0 17 103 3 0 0 0 0 1 2637 ## 94 0 29 123 1 1 0 0 0 1 2663 ## 95 0 26 113 1 1 0 0 0 0 2665 "],["deskriptiv.html", "3 . fejezet Deskriptív statisztika 3.1 A deskriptív statisztikáról általában 3.2 A deskriptív statisztika módszereinek csoportosításáról 3.3 Minségi változó egyváltozós elemzése 3.4 Mennyiségi változó egyváltozós elemzése 3.5 Minségi változók kétváltozós elemzése 3.6 Mennyiségi változók kétváltozós elemzése 3.7 További többváltozós elemzések", " 3 . fejezet Deskriptív statisztika Ebben az fejezetben a statisztika deskriptív ágával fogunk foglalkozni. Már utaltunk rá, hogy deskriptív statisztikáról akkor beszélünk, amikor kizárólag a mintában lév információt igyekszünk valamilyen módon megragadni (és nem tördünk azzal, hogy a minta maga is csak a valóság egy ,,szelete, szebben megfogalmazva: figyelmen kívül hagyjuk a mintavételi helyzetet). Elször ezt a gondolatot fogjuk pontosítani, közelebbrl körüljárni; majd pedig megismerkedünk a leíró statisztika legalapvetbb módszereivel. Látni fogunk grafikus és analitikus módszereket, foglalkozunk egy- és (röviden) többváltozós helyzetekkel; az ismertetést pedig a vizsgált változók mérési skálája (@ref{alapokvaltozok}. alfejezet) szerint végezzük. (Azzal, hogy a nominális és az ordinális, illetve az intervallum- és arányskálán mért változókat nem választjuk szét, hanem minségi és mennyiségi változókról fogunk beszélni.) Ezek után az olvasó számára ismers lesz a mai orvostudományi cikkekben alkalmazott deskriptív eszköztár túlnyomó része; az elemi eszközöknek pedig szinte egésze. Ebben a fejezetben a már említett módon a Low Infant Birth Weight adatbázist fogjuk futó példaként használni a módszertani mondanivaló illusztrálására. Az ábrák és a számítások statisztikai környezet alatt készültek. 3.1 A deskriptív statisztikáról általában Amint már többször említettük, a deskriptív statisztika definíciós jellemzje, hogy kizárólag a mintában lév információval tördik, számára az az ,,univerzum, és teljes mértékben figyelmen kívül hagyja azt a kérdéskört, hogy a mintában lév információ hogyan viszonyul a sokaságban lév információhoz. Innen ered a módszer neve is: a deskripció leírást jelent, azaz a deskriptív módszerek pusztán a minta  valamilyen szempontból ,,jó  leírását célozzák meg (nem pedig következtetést a sokaságra). Nem véletlen, hogy ebben a kontextusban nagyon sokszor minta helyett mondunk (tükrözve, hogy itt igazából nincs is jelentsége annak, hogy az adataink csak  a szó statisztikai értelmében  egy mintát jelentenek). A ,,jó leírás alatt legtöbbször azt értjük, hogy a mintában lév információt úgy próbáljuk tömöríteni, hogy közben  valamilyen elemzési célra tekintettel  kiemeljük a lényeget. Erre azért van szükség, mert a legtöbb esetben a mintában lév információ (még ha csak néhány változóra, és néhány tucat megfigyelési egységre is gondolunk) feldolgozhatatlan ,,ránézésre. A számok tengerébl még a legalapvetbb kérdésekre sem tudnánk válaszolni. Szükség van tehát olyan módszerekre, melyek ,,emészthetvé teszik ezt a számtengert: csökkentik a bonyolultságát, hogy tudjuk értelmezni azt, fel tudjuk használni kérdések megválaszolásához, illetve új megállapítások eléréséhez. Nyilvánvaló, hogy a bonyolultság csökkentése csak úgy lehetséges, ha információt hagyunk el. Az egész mvelet kritikus pontja épp ez: annak megválasztása, hogy mennyi információt hanyagoljunk el (és persze hogyan). A ,,hogyan szerepe triviális: ha egy adott, mennyiségi változóra vonatkozó 100 elem mintából elhagyjuk az els 99 elemet, akkor ugyan egyetlen számmá, azaz teljesen áttekinthetvé alakítjuk az információt  csak épp nyilván semmit nem érünk el vele. Ha viszont kiszámoljuk az átlagot, akkor ugyanúgy egyetlen számot kapunk, de immár úgy, hogy annak van értelme, azaz felhasználhatjuk kérdések megválaszolásához, illetve új megállapítások eléréséhez. A meghatározó kulcskérdés az elhanyagolásban (az információtömörítésben) tehát a ,,mennyit. Látható, hogy trade-off áll fenn az áttekinthetség, és a reprodukciós hség között: minél többet hanyagolunk el, annál inkább segítjük az áttekinthetséget, de annál többet vesztünk az eredeti információ hséges reprodukciójából. A deskriptív statisztika igazi sava-borsa (végeredményben a legtöbb módszer, így vagy úgy, de ebben foglal el egy álláspontot) a jó kompromisszum megkötése a kett között. Példának okáért, adatbázisunkban a születési tömeg változó megfigyelései így néznek ki: birthwt$bwt ## [1] 2523 2551 2557 2594 2600 2622 2637 2637 2663 2665 2722 2733 2751 2750 2769 ## [16] 2769 2778 2782 2807 2821 2835 2835 2836 2863 2877 2877 2906 2920 2920 2920 ## [31] 2920 2948 2948 2977 2977 2977 2977 2922 3005 3033 3042 3062 3062 3062 3062 ## [46] 3062 3080 3090 3090 3090 3100 3104 3132 3147 3175 3175 3203 3203 3203 3225 ## [61] 3225 3232 3232 3234 3260 3274 3274 3303 3317 3317 3317 3321 3331 3374 3374 ## [76] 3402 3416 3430 3444 3459 3460 3473 3544 3487 3544 3572 3572 3586 3600 3614 ## [91] 3614 3629 3629 3637 3643 3651 3651 3651 3651 3699 3728 3756 3770 3770 3770 ## [106] 3790 3799 3827 3856 3860 3860 3884 3884 3912 3940 3941 3941 3969 3983 3997 ## [121] 3997 4054 4054 4111 4153 4167 4174 4238 4593 4990 709 1021 1135 1330 1474 ## [136] 1588 1588 1701 1729 1790 1818 1885 1893 1899 1928 1928 1928 1936 1970 2055 ## [151] 2055 2082 2084 2084 2100 2125 2126 2187 2187 2211 2225 2240 2240 2282 2296 ## [166] 2296 2301 2325 2353 2353 2367 2381 2381 2381 2410 2410 2410 2414 2424 2438 ## [181] 2442 2450 2466 2466 2466 2495 2495 2495 2495 Ezt a megadást nevezhetnénk az egyik végpontnak ebben a kompromisszumban: 100% reprodukciós hség, de  szinte  0% áttekinthetség. Ez a legalapvetbb kérdések megválaszolását, a legalapvetbb észrevételek elérését is lehetetlenné teszi. Másik végpontnak vehetjük azt, amikor a fenti adatoknak csak az átlagát adjuk meg 2944.6. Ez 0%-hoz közeli reprodukciós hséget jelent (189 számból 1-et ,,gyártottunk, szinte semmit nem tudunk reprodukálni az eredeti adatbázisból), viszont remek az áttekinthetsége (például azonnal látható, hogy milyen érték körül csoportosulnak az adatok). Az igazán érdekes az, hogy  természetszerleg  a két végpont között számos egyéb kompromisszumot köthetünk. Megadhatjuk például (az utóbbi végponttól az elbbi felé haladva) az adatok átlagát és szórását: 2944.6 \\(\\pm\\) 729.2, az adatok átlagát, mediánját, szórását és interkvartilis terjedelmét: 2944.6 (2977) \\(\\pm\\) 729.2 (1073), vagy épp az adatok átlagát, mediánját, szórását, interkvartilis terjedelmét, illetve minimumát és maximumát: 2944.6 (2977) \\(\\pm\\) 729.2 (1073) [709-4990]. Látszik, hogy minden ilyen megadás egyfajta kompromisszum: egyre több információt rzünk meg (egyre kevesebb az adatvesztés, hségesebb a reprodukció), viszont közben romlik a megadás áttekinthetsége. Összefoglalva tehát megállapíthatjuk, hogy bár az információtömörítés ugyan szükségképp adatvesztést jelent, ez azonban nem feltétlenül baj, épp ellenkezleg: ez teszi lehetvé, hogy a fontosat észrevegyük. A kulcs a kett közötti egyensúlyozás. 3.2 A deskriptív statisztika módszereinek csoportosításáról Azért, hogy az igen nagy számú leíró statisztikai módszert áttekintheten tudjuk tárgyalni, érdemes megismerkedni pár szemponttal, melyek mentén e módszerek jellegzetes, és gyakorlati szempontból fontos csoportokba sorolhatóak. 3.2.1 Grafikus és analitikus módszerek A fent mutatott példák (átlagtól szóráson át a terjedelemig) mind ún. analitikus eszközök voltak, azaz a (számszer) információból számszer, csak épp tömörebb, lényeget kiemel információt gyártottak. Az analitikus módszerek tipikus példái a mutatószámok, mint amilyen az átlag vagy a szórás, bár léteznek ennél komplexebb (nem egyetlen számból álló) eredményt szolgáltató analitikus eszközök is  az azonban közös pont, hogy mindegyik számszer kimenetet ad. Ezzel állnak szemben a grafikus módszerek, melyek a bemen (számszer) információból valamilyen képi megjelenítést konstruálnak. Szokás ezért az ilyet adatvizualizációnak is nevezni, bár ezt a megnevezést gyakran csak a komplexebb módszerekre alkalmazzák. A grafikus módszerek általában kevésbé tömörek és kevésbé objektivizálhatóak (ami gond lehet, ha például összehasonlításra van szükség), de cserébe nagyon sokszor jobban értelmezhet benyomást tudnak adni a vizsgált adatbázisról. Ennek hátterében az van, hogy az emberi agy különösen alkalmas struktúrák azonosítására, vizsgálatára grafikus információkban; így ha ügyesen tudjuk vizualizálni adatbázisunk tartalmát, azzal nagyban megkönnyíthetjük az elemzését. Nem véletlen, hogy John Wilder Tukey egyszer azt mondta: ``There is no excuse for failing to plot and look! (,,Nincs mentség arra, ha nem ábrázoljuk az adatokat és nézünk egyszeren rá!). 3.2.2 Egy- és többváltozós módszerek Szemben azzal, amit sokan elsre gondolnának, hogy ti. az egyváltozós módszerekkel egyetlen változót vizsgálunk (míg a többváltozósakkal többet), valójában egyváltozós módszerekkel is vizsgálhatunk akárhány változót. A különbség tehát nem ez, hanem az, hogy az egyváltozós módszerekkel egy idben egyetlen változót vizsgálunk csak, míg a többváltozós módszerek egyidejleg is több változót tekintenek. (Ha megadjuk, hogy pontosan hányat, akkor ezt az elnevezésben is szerepeltethetjük, pl. kétváltozós vizsgálat, háromváltozós vizsgálat stb.) Hogy mit értünk az alatt, hogy ,,egy idben? Képzeljünk el egy adatbázist, melyben emberek testmagasságát és testtömegét mértük le. Okkal várjuk azt, hogy a nagyobb testmagasság tendenciájában nagyobb testtömeggel jár együtt, tehát azoknak, akiknek nagyobb a testmagasságuk, várhatóan nagyobb a testtömegük is. Igen ám, de ha a testmagasságot vizsgáljuk, vagy a testtömeget, akkor ezt soha nem vennénk észre! Vegyük észre, hogy bármilyen alapos elemzést is végeznénk (beleértve akár az összes megfigyelés tömörítés nélküli felsorolását), soha nem jövünk rá erre a kapcsolatra  hiszen a külön-külön végzett vizsgálatokban nem tudjuk összerendelni az ugyanazon emberhez tartozó testmagasságot és testtömeget (épp ez a definíciója a külön-külön végzésnek). Amit tehát elvesztünk, az a változók közötti kérdésköre. Éppen ezért mondhatjuk azt, hogy egy többváltozós vizsgálat több, mint több egyváltozós vizsgálat  hiszen itt már megjelenik a változók közötti kapcsolatok kérdése is. Végezetül megjegyezzük, hogy a többváltozós kategóriát néha szétbontják, arra tekintettel, hogy a többváltozós elemzés klasszikus arzenálja csak egy-két tucat változóig alkalmazható hatásosan (st, igazán hatásosan inkább csak 10-nél is kevesebb változóra). Az e fölötti tartományban néha megkülönböztetésül sokváltozós adatelemzésrl beszélnek. 3.2.3 A vizsgált változó(k) mérési skálája A leíró statisztika módszerei jellegzetesen eltérnek aszerint is, hogy milyen mérési skálán mért változó elemzésérl van szó. Amint már említettük is, az ordinális és nominális változókat nem fogjuk megkülönböztetni, és egységesen minségi változókról fogunk beszélni, hasonlóképp az intervallum- és arányskálán mért változók esetében is egységesen mennyiségi változókról lesz szó. (A különbségekre csak utalni fogunk.) 3.3 Minségi változó egyváltozós elemzése Minségi változóra jó példa adatbázisunk rassz (race) változója, mely az alany rassz szerinti hovatartozását adja meg és ilyen módon nominális. 3.3.1 Analitikus eszközök Ilyen változó elemzésének tipikus analitikus eszköze az ún. gyakorisági sor. A gyakorisági sor a változó lehetséges kimeneteit (kategóriáit) tartalmazza, együtt azzal, hogy az adott kimenetbl hány fordult el az adatbázisban. Az ilyen ,,darabszámot a statisztikában általában is gyakoriságnak nevezik, és \\(f\\)-fel jelölik. (Illetve, ha utalni akarunk arra, hogy az \\(i\\)-edik kategória gyakoriságáról van szó, akkor \\(f_i\\)-vel.) Általában \\(n\\)-nel szokás jelölni a mintanagyságot, így nyilván \\(\\sum_{i=1}^n f_i = n\\). Szokás még beszélni relatív gyakoriságról is, ami nem más, mint az elbbi (abszolút) gyakoriság osztva a mintanagysággal (azaz \\(n\\)-nel). A relatív gyakoriság tehát azt mutatja meg, hogy egy kategóriába a megfigyelési egységek mekkora hányada esik. Nyilván \\(\\sum_{i=1}^n g_i = 1\\). Példának okáért, a rassz változó gyakorisági sora: birthwt$race &lt;- factor(birthwt$race, levels = 1:3, labels = c(&quot;Kaukázusi&quot;, &quot;Afroamerikai&quot;, &quot;Egyéb&quot;)) table(birthwt$race) ## ## Kaukázusi Afroamerikai Egyéb ## 96 26 67 prop.table(table(birthwt$race)) ## ## Kaukázusi Afroamerikai Egyéb ## 0.5 0.1 0.4 cbind(table(birthwt$race), prop.table(table(birthwt$race))) ## [,1] [,2] ## Kaukázusi 96 0.5 ## Afroamerikai 26 0.1 ## Egyéb 67 0.4 Megjegyezzük, hogy a teljes relatív gyakorisági sort a statisztikusok nagyon gyakran a változó megoszlásának hívják. Vegyük észre, hogy ebben a speciális esetben az információtömörítés igazából semmilyen információveszteséggel nem járt: ez a három szám hordoz információt errl a változóról mint az eredeti 189 szám! Ez azonban egy abszolút speciális eset, ami kizárólag a változó minségi mivoltának volt köszönhet. A gyakorisági soron kívül egy mutatószámnak van még értelme ennél a mérési skálánál: a . A módusz (jele: \\(\\mathrm{Mo}\\)) nem más, mint a leggyakoribb kimenet (tehát az a kimenet, melyhez tartozó gyakoriság a legnagyobb az adatbázisban). Nagyon formalizálva ezt írhatnánk: \\[ \\mathrm{Mo}=\\mathop{\\mathrm{arg\\,max}}_i f_i. \\] A példánkban tehát a rassz módusza a kaukázusi. Már most megjegyezzük, hogy a módusz ún. középérték, ezen belül is helyzeti középérték; de e fogalmaknak majd a mennyiségi változóknál lesz szemléletesebb tartalma. Érdemes megfigyelni, hogy itt viszont már érvényesül a kompromisszum a hség és az áttekinthetség között! Nyilván még áttekinthetbb, ha a fenti 3 szám megadása helyett annyit mondunk, hogy ,,a módusz a kaukázusi, de ebben már nagyon is lesz információveszteség: nem tudhatjuk, hogy a 189-bl 189 kaukázusi vagy 64 (vagy épp 96), és semmit nem tudunk a többi kategória gyakoriságáról. Végezetül megjegyezzük, hogy az ordinalitás csak annyit módosít a fentieken, hogy a gyakorisági sorban a kategóriák felsorolási sorrendje kötött lesz (nominális esetben, mint amilyen a mostani példánk is volt, nyilván érdektelen, hogy milyen sorrendben adjuk meg a kategóriákat, tetszlegesen felcserélhettük volna a sorokat anélkül, hogy az érdemi változást okozott volna). Ami a mutatószámokat illeti, ordinális esetben elvileg már definiálható lenne a medián fogalma is, de mivel használata itt nem tipikus, a bevezetését meghagyjuk késbbre. 3.3.2 Grafikus eszközök A minségi változók grafikus elemzése lényegében a gyakorisági sor vizualizálását jelenti. Ennek két, gyakorlatban legtipikusabb eszköze az oszlopdiagram és a kördiagram. Az elbbi oszlopok magasságával, az utóbbi körcikkek területével szemlélteti a gyakoriságokat. (Bár ez utóbbi, jellegébl adódóan, igazából csak relatív gyakoriságokat tud szemléltetni. Oszlopdiagrammal gyakoriság és relatív gyakoriság is szemléltethet; st, a kett lényegében ekvivalens, csak a függleges tengely skálázása lesz más.) Oszlopdiagramot használtunk a 3.1. ábrán. barplot(table(birthwt$race), xlab = &quot;Rassz&quot;, ylab = &quot;Gyakoriság [f]&quot;) Figure 3.1: Példa egy minségi változó ábrázolására oszlopdiagrammal. Az oszlop- és kördiagramok használata kapcsán megjegyzend, hogy tudományos munkákban általában az oszlopdiagram a preferált, pszichológiai vizsgálatok szerint ugyanis az emberi szem jobban tud lineáris mértékeket kezelni és értelmezni, mint területet. Az egyetlen megfontolás, ami mégis az oszlopdiagram ellen szólhat néha, hogy az oszlopok kirajzolási sorrendje már implikál egyfajta sorrendezést (a természetes balról-jobbra olvasás miatt), ami adott esetben nem következik az változó tartalmából. Az ordinalitás e téren nem sok változást okoz: az oszlopok sorrendje kötött lesz, illetve ábrázolhatóvá válik a kumulált gyakoriság is (természetesen csak oszlopdiagrammal). 3.4 Mennyiségi változó egyváltozós elemzése Mennyiségi változóra jó példa adatbázisunk születési tömeg () változója, mely az alany születési tömegét adja meg (és így arányskálán mért, egész pontosan). 3.4.1 Analitikus eszközök Az analitikus eszközök közül elször most is a gyakorisági sort, majd a különböz mutatószámokat tárgyaljuk meg. 3.4.1.1 Gyakorisági sor Gyakorisági sor természetesen mennyiségi változóra is készíthet, de csak módosításokkal. Annak ugyanis, hogy megszámoljuk, hogy az egyes elforduló kimenetekbl mennyi van, nincs sok értelme (hogy egy példával illusztráljuk: az itt tipikus folytonos változóknál könnyen lehet, hogy minden egyes elforduló kimenetbl csak egyetlen egy lesz). A problémát nyilván a folytonosság jelenti, ami ellen úgy védekezhetünk, hogy nem adott értéket felvev} megfigyelési egységek számát adjuk meg, hanem adott intervallumba esek számát. Így kapjuk az osztályközös gyakorisági sort. (Az elnevezés arra utal, hogy osztályközöket hozunk létre  így fogjuk hívni az elbb említett intervallumokat.) A gyakoriság, relatív gyakoriság, kumulált gyakoriság és kumulált relatív gyakoriság értelmezése változatlan. A születési tömeg változó osztályközös gyakorisági sora (precízebben szólva: egy lehetséges osztályközös gyakorisági sora; hiszen ez már függeni fog az osztályközök megválasztásától is), a következ: tab &lt;- table(cut(birthwt$bwt, seq(500, 5000, 500))) cbind(Ci0 = seq(500, 4500, 500), Ci1 = seq(1000, 5000, 500), fi = tab, gi = prop.table(tab)) ## Ci0 Ci1 fi gi ## (500,1e+03] 500 1000 1 0.005 ## (1e+03,1.5e+03] 1000 1500 4 0.021 ## (1.5e+03,2e+03] 1500 2000 14 0.074 ## (2e+03,2.5e+03] 2000 2500 40 0.212 ## (2.5e+03,3e+03] 2500 3000 38 0.201 ## (3e+03,3.5e+03] 3000 3500 45 0.238 ## (3.5e+03,4e+03] 3500 4000 38 0.201 ## (4e+03,4.5e+03] 4000 4500 7 0.037 ## (4.5e+03,5e+03] 4500 5000 2 0.011 Itt \\(C_{i0}\\) és \\(C_{i1}\\) az \\(i\\)-edik osztályköz alsó és fels határát jelöli, rendre. (Az megállapodás kérdése, hogy a határon lév megfigyelési egységeket, például egy pont 2000 grammos újszülöttet hová sorolunk, ennek természetesen csak a kerekítésbl adódó diszkrétség miatt van egyáltalán jelentsége.) Vegyük észre, hogy ez a megoldás lényegében azt jelenti, hogy a mennyiségi változónkat els lépésben ,,lefokozzuk minségi változóvá, és utána alkalmazzuk  mint teljesen közönséges minségi változóra  a korábban megismert módszert. Elöljáróban jegyezzük meg, hogy itt már a gyakorisági sor  szemben a minségi esettel  igenis információvesztéssel jár: lehet 14 újszülött 1501 grammos, és lehet mind a 14 1999 grammos, mindkét esetben ugyanúgy a fenti osztályközös gyakorisági sort kapjuk. Az információvesztés mértékét nyilván az osztályközök hossza (a felosztás ,,finomsága) fogja meghatározni. A sor eltti zárójeles megjegyzésünk már utal arra, hogy mi az osztályközös gyakorisági sorok használatának legnagyobb kihívása: az osztályközök helyes megválasztása. Az információveszteség minimalizálása szempontjából nyilván a minél szkebb osztályközök a jobbak, viszont túlzásba ezt sem lehet vinni, különben értelmét veszti az egész eszköz, azáltal, hogy megsznik a lényegkiemel jelleg. (Ha egyre jobban és jobban szkítjük az osztályközöket, akkor egy id után visszajutunk oda, hogy az intervallumok túlnyomó részében 0 lesz a gyakoriság, a többiben pedig 1-1  azaz lényegében visszakapjuk a minta ,,felsorolását.) Az egyetlen dolog, ami univerzálisan segít ezen, az a mintanagyság növelése (hiszen lehetvé teszi az osztályközök szkítését úgy, hogy közben várhatóan nem csökken az egy osztályközbe es megfigyelési egységek száma). Ráadásul az osztópontok megválasztása nem csak az információveszteség szempontjából fontos. Az, hogy a gyakorisági sor milyen képest sugall számunkra a vizsgált változóról  sajnos  nagyban változhat akár az osztópontok nem túl lényeges áthelyezésének hatására is, különösen kis mintanagyságnál. Éppen ezért jelent a gyakorlatban komoly kihívást az osztályközök határainak jó megválasztása. Hogy ezt hogyan tegyük meg, arra alapveten két lehetségünk van. Az egyik út az, hogy tárgyterületi információkat használunk fel, azaz megpróbálunk  az adott változó jelentését is figyelembe véve  szakmailag értelmes, tartalommal bíró osztópontokat találni. (A fenti gyakorisági sor példa erre, hiszen kerek, emberi szem számára kényelmesen értelmezhet osztópontokat vettünk fel.) A másik lehetség, hogy tisztán statisztikai alapon (tehát a változó tárgyterületi jelentésének felhasználása nélkül) döntünk  vannak módszerek, melyek pusztán a megfigyelések statisztikai jellemzi (nagyság, szóródás stb.) alapján igyekeznek ,,kitalálni, hogy hová érdemes rakni az osztópontokat ahhoz, hogy a lehet leginformatívabb gyakorisági sort kapjuk. Példának okáért, az egyik ilyen ismert analitikus szabály a Sturges-szabály, ami azt javasolja, hogy \\(\\left\\lceil \\log_2 n+1\\right\\rceil\\) darab azonos szélesség osztályközt vegyünk fel a mintaminimum és -maximum között. 3.4.1.2 Mutatószámok A mutatószámok a megfigyelések valamilyen jellemzjét próbálják meg egy-egy számba tömörítve megragadni. A következkben aszerint csoportosítva mutatjuk be ket, hogy mi ez a megragadott jellemz. 3.4.1.2.1 Középértékek (centrális tendencia) Centrális tendencia alatt azt értjük, hogy mi az az érték, ami körül csoportosulnak a megfigyelések. Függen a konkrét mutatótól, olyanokra gondolhatunk ez alatt, mint ,,közepes, ,,tipikus vagy ,,átlagos érték. A legtöbb statisztikai alkalmazás szempontjából ez a legfontosabb jellemzje a változónak, ezért ha csak egyetlen számmal jellemezhetjük a változót, az tipikusan a centrális tendencia valamilyen leírója lesz. Ezeket a mutatószámokat általában középértéknek vagy helyzetmutatónak nevezik. A centrális tendencia legismertebb mutatója a (számtani) átlag, jele \\(\\overline{x}\\). Definíciószeren nem más, mint az az szám, amivel helyettesítve minden megfigyelési egység értékét, az ún. értékösszeg (a változó megfigyeléseinek összege) változatlan maradna: \\[ \\overline{x}=\\frac{\\sum_{i=1}^n x_i}{n}. \\] Azonnal látható, hogy ennek akkor van értelme, ha a különböz megfigyelések számtani összege valamilyen értelmes tartalommal bír. (Van például értelme beszélni egy osztály átlagos testtömegérl, hiszen a testtömegek összege értelmes kifejezés, megadja például, hogy mennyit mutatna egy mérleg, ha mindenki ráállná.) Ha azonban a változó olyan, hogy nem az megfigyelések összegének van értelme, akkor a számtani átlag használata félrevezet lehet, és mással kell helyettesíteni  például, ha a megfigyelések összege helyett azok szorzata a tárgyterületileg értelmes, akkor az ún. mértani átlaggal. (Tipikus példa erre az, ha a változó valamilyen növekedési ütemet jelent idben. Ha egy alany testtömege egy évben 1,2-szeresére ntt, rákövetkez évben pedig 1,3-szeresére, akkor az össznövekedés nyilván nem a növekedések összege (\\(1,\\!2 + 1,\\!2 = 2,\\!4\\)), hanem azok szorzata (\\(1,\\!2 \\cdot 1,\\!2 = 1,\\!44\\)) lesz.) A születési tömegek átlaga 2944.6 gramm, ami azt jelenti, hogy az adatbázisban szerepl újszülöttek össz-testtömege akkor maradna változatlan, ha mindegyikük 2944.6 gramm lenne. Az átlag ún. számított középérték, mivel valamilyen számszer összefüggésben van a megfigyelések értékeivel. Az átlag elnye, hogy rendkívül közismert, mindenki számára kényelmesen kezelhet, szokásos gondolkodásunkhoz közel álló mutató. (Ez olyannyira ers tényez, hogy nagyon sok orvosi publikáció még akkor is erlteti az átlag használatát, amikor az  a mindjárt részletezend okokból  nem célszer.) Az átlag legnagyobb hátránya, hogy nem robusztus. Egy statisztikai mutatószám robusztussága azt méri, hogy mennyire érzékeny arra, ha a mintában a többi értéktl, a csoportosulás alaptendenciájától jelentsen eltér érték vagy értékek vannak. Az ilyen megfigyeléseket egyébként nagyon gyakran outliernek is nevezik. (,,Érzékenység alatt azt értjük, hogy a mutatót mennyire tudja befolyásolni, eredeti értékétl eltéríteni ilyen outlierek jelenléte.) Az átlag ilyen szempontból extrém rossz mutató: egyrészt bármelyik megfigyelés bármilyen megváltozása módosítja az átlag értékét, de ami az igazán nagy baj, hogy ha egyetlen megfigyelés is tart a végtelenhez, úgy az átlag is tart a végtelenhez, függetlenül az összes többi megfigyeléstl, és függetlenül a minta nagyságától. Mindez azt mondja nekünk, hogy ha csak egyetlen outlier is van a mintában, már az is képes arra, hogy teljesen értelmetlenné tegye az átlagot. (Hiszen ha van egy ilyen outlier a mintában, akkor az átlag pont hogy nem a minta ,,közepes értékét fogja mutatni, hanem egyre inkább az outlierét, minél jobban kilóg.) Megjegyezzük, hogy pontosan emiatt az átlag használata a centrális tendencia jellemzésére nem csak gyakorlati szempontból lehet problémás (adatrögzítési hibákból, adatbázis-sérülésekbl eredeti outlierek), hanem elméletileg is ellenjavallt, ha a változó olyan, hogy fel kell készülni kis számú, de a többitl lényegesen nagyobb vagy kisebb megfigyelés jelenlétére. (Ez fordulhat el  mindenféle adatrögzítési és egyéb hiba nélkül is!  például ún. aszimmetrikus eloszlásoknál, melyekrl késbb fogunk részletesebben beszélni.) Épp ezen a robusztussági problémán igyekszik javítani a trimmelt (vagy nyesett) átlag: ezt úgy kapjuk, hogy elhagyjuk a legkisebb és legnagyobb adott számú elemet, és csak a maradékot átlagoljuk ki. Tipikusan az elhagyott megfigyelések száma alul és felül is a mintanagyság 2,5%-a; ebben az esetben 5%-os trimmelt átlagról beszélünk. (Bár elsre ez szokatlan mutatónak tnhet, és a tudományos irodalomban tényleg ritkábban is használják, de számos pontozásos sportágban épp ilyen elven alakítják ki a zsri ,,átlagos pontszámát.) A születési tömegek 5%-os trimmelt átlaga 2957.4 gramm, ami egyúttal azt is mutatja, lévén, hogy közel van a szokásos átlaghoz, hogy a születési tömegek aránylag szimmetrikus eloszlásúak, vélheten komoly outlier nélkül. Alapveten más megközelítését jelenti a centrális tendencia megragadásának a medián használata, melynek jele \\(\\mathrm{Me}_x\\). A medián nem más, mint a nagyság szerint sorbarendezett megfigyelések közül a középs. (Amennyiben a mintanagyság páros, úgy nyilván két ,,középs is van, ez esetben megállapodás kérdése, hogy mit nevezünk mediánnak; vehetjük például a kett átlagát.) Úgy is szoktak fogalmazni, hogy a medián felezpont, az az érték, amirl elmondható, hogy alatta és felette is egyaránt ugyanannyi mintaelem (az összes fele-fele) található. Értelemszer, hogy a medián szintén a centrális tendenciát jellemzi, csak épp kevésbé megszokott módon, mint az átlag  ez egyúttal használatának egyik f gátja is: sok ember számára a medián tartalma (és egyáltalán, értelme) kevésbé ismert, így e mutató nem annyira jól kezelhet. Elnye viszont a robusztusság, ilyen szempontból az átlaggal szemben a másik végpontot képviseli: míg az átlag extrém érzékeny volt, addig a medián extrém robusztus. A minta minden medián feletti értéke (az egyszerség kedvéért most gondoljunk páratlan mintanagyságra) tetszlegesen megnövelhet (akár az összes egyszerre is), vagy a medián alatti értékek tetszlegesen lecsökkenthetek (akár az összes egyszerre is), vagy akár a kett együtt is, a medián értéke nem változik! Hátránya, hogy a jó robusztusságért cserében kevesebb információt használ fel a mintából; ezt épp a mintaértékek meglehetsen szabad ,,állítgathatósága mutatja. (Hogy ez miért baj, az precízen csak induktív statisztikai keretben lehet megérteni, az ottani tárgyalás után már érthet lesz, hogy mit jelent az, hogy a medián kevésbé hatásos becsl mint az átlag.) A tanulság az, hogy ha feltehet, hogy a háttéreloszlás szimmetrikus-közeli, akkor érdemes átlagot használni, ha nem, vagy outlierek jelenlétére is fel kell készülni (azaz indokolt robusztus statisztika használata), akkor jobb a medián ilyen szempontból. A születési tömegek mediánja 2977 gramm, azaz a 2977 gramm az a testtömeg, amirl elmondható, hogy az újszülöttek fele kisebb ennél, fele nagyobb. Ahogy a medián a minta ,,felezpontja ugyanúgy definiálhatók általános osztópontok; ezeket kvantiliseknek nevezzük. A \\(p\\)-kvantilis (\\(0&lt;p&lt;1\\)) az az érték, amirl elmondható, hogy a megfigyelések \\(p\\)-ed része kisebb nála, \\(\\left(1-p\\right)\\)-ed része nagyobb nála. (Tehát a medián az \\(1/2\\)-kvantilis.) Gyakorlati szempontból nagyobb jelentsége van még a negyedelpontoknak, melyek neve kvartilis. Ilyenbl tehát nyilván három van: a \\(p=1/4,2/4=1/2,3/4\\)-kvantilis, ezek közül a középs persze ugyanaz mint a medián. A másik kettt alsó és fels kvartilisnek szokták nevezni, és \\(Q_1\\)-gyel, illetve \\(Q_3\\)-mal jelölik. Tehát például \\(Q_1\\) az a szám, amire igaz, hogy a minta egynegyede (darabszámra) nála kisebb érték, háromnegyede nála nagyobb. Ezek valójában már nem is a centrális tendenciát, hanem általában az eloszlás alakját mutatják, mégpedig robusztus módon (ugyanazon okból, mint amit a mediánnál is láttunk). Ritkábban, de szokták használni ugyanerre a célra a tizedelpontokat, nevük decilis (\\(D_1,D_2,\\ldots,D_9\\)) és a századolópontokat, nevük percentilis (\\(P_1,P_2,\\ldots,P_{99}\\)). A módusz használatának a folytonosság miatt általában nincs értelme mennyiségi változó esetén, ahogy azt már említettük is. Értelmet csak az ad neki, ha diszkretizáljuk (csoportosítjuk) az adatokat, ahogy az a gyakorisági sorral történt is. Ilyenkor már van értelme móduszról beszélni, persze ekkor már csak osztályköz szintjén  szokás ezt modális osztályköznek is nevezni. Például a születési tömegek fent közölt osztályközös gyakorisági sorában (ne feledjük, itt már az is számít, hogy melyik osztályközös gyakorisági sorra vonatkozóan adjuk meg!) a modális osztályköz a 30003500 gramm. A módusz és a medián ún. helyzeti középérték, mivel nem számítás eredményeként adódnak, hanem a többi megfigyeléshez képest elfoglalt helyzetük tünteti ki ket. Ennek kapcsán azt is megjegyezzük, hogy átlagot, mediánt (és általában minden egyéb mutatószámot is) lehetséges osztályközös gyakorisági sorból (a nyers mintaelemek ismerete nélkül is) számolni, persze ekkor már csak közelít jelleggel. 3.4.1.2.2 Szóródás Szóródásnak nevezzük azt, hogy a megfigyelések milyen szorosan csoportosulnak azon érték körül, ami körül csoportosulnak (lásd a centrális tendenciát!), más szóval mennyire ingadoznak a megfigyelések, mekkora változékonyság van bennük. A gyakorlatban ez a második legfontosabb kérdés: ha csak egy jellemzt adhatunk meg, akkor az a centrális tendencia lesz, de ha kettt, akkor megadjuk azt is, hogy mekkora a szóródás. A minta szóródásának legegyszerbb mérszáma a legkisebb (\\(\\mathrm{Min}\\)) és a legnagyobb (\\(\\mathrm{Max}\\)) mintaelem értéke, a mintaminimum és mintamaximum, illetve kettejük különbsége, melyet terjedelemnek nevezünk és \\(R\\)-rel jelölünk: \\(R=\\mathrm{Max}-\\mathrm{Min}\\). Ezek elnye, hogy teljesen egyértelm a tartalmuk, hátrányuk, hogy rendkívül érzékenyek arra, hogy konkrétan milyen mintát vettünk a sokaságból, ezért következtetési célokra nem is szokták alkalmazni. A születési tömegek mintaminimuma 709 gramm, mintamaximuma 4990 gramm, így e változó terjedelme 4281gramm. A leggyakoribb általános célú mutatója a szóródásnak a , jele általában \\(s_x\\) vagy \\(\\sigma_x\\). (A kett neve nem keverend: a ,,szóródás a jellemz, a ,,szórás egy lehetséges mutatószáma a szóródásnak.) A szórás nem más, mint a megfigyelések átlagtól vett átlagos eltérése. Ez utóbbi átlag alatt négyzetes átlagot értve  egyszer számtani átlag nem lenne jó, hiszen azzal a pozitív és negatív irányú eltérések csökkentenék (st, belátható, hogy kioltanák) egymás hatását. Azaz: \\[ s_x=\\sqrt{\\frac{\\sum_{i=1}^n \\left(x_i-\\overline{x}\\right)^2}{n}}. \\] Ennek a négyzetét szokás szórásnégyzetnek vagy varianciának nevezni. Deskriptív esetben néha inkább mintaszórást illetve mintavarianciát mondanak (hogy a megfelel valószínségszámítási fogalomtól megkülönböztessék). A fent definiált mutatót szokás precízen korrigálatlan mintaszórásnak nevezni, ezzel szemben a korrigált mintaszórás: \\[ s_x^{\\ast}=\\sqrt{\\frac{\\sum_{i=1}^n \\left(x_i-\\overline{x}\\right)^2}{n-1}}. \\] A különbségük oka csak a következtet statisztikában válik világossá (a korrigálatlan mintavariancia, els ránézésre talán meglep módon, nem torzítatlan becslje a sokasági varianciának). A születési tömegek korrigált mintaszórása 729.2 gramm, tehát az újszülöttek testtömegeinek átlaguk körül vett ingadozásának (négyzetes) átlaga 729.2 gramm. A szórás hátránya, hogy  az átlaghoz hasonlóan  nem robusztus mutató. (Egyrészt azért, mert maga is az eltérések négyzetét használja, ami érzékeny a kilógó értékekre, másrészt azért, mert a eltéréseket a nem-robusztus átlagtól veszi.) Egyik lehetséges megoldás az interkvartilis terjedelem (jele \\(IQR\\)) használata, ami a fels és az alsó kvartilis különbsége: \\[ IQR=Q_3-Q_1. \\] Az interkvartilis terjedelem a robusztus kvartiliseken alapul, így robusztus mutató, és könnyen látható, hogy tartalmilag a szóródást jellemzi, hiszen minél jobban szóródott az eloszlás, annál távolabb lesz az alsó és a fels negyedelpontja. A születési tömegek interkvartilis terjedelme 1073 gramm, tehát az a tömeg, ami fölött az újszülöttek egynegyede (és alatta háromnegyede) van, 1073 grammal nagyobb annál a tömegnél, ami fölött az újszülöttek háromnegyede (és alatta egynegyede) van. A másik lehetség a szórás ,,megjavítása, olyan módon, hogy az eltéréseknek nem a négyzetét, hanem az abszolút értékét vesszük. (Ezzel a kapott mennyiség matematikai kezelhetségét rontjuk, hiszen a négyzetreemelés jobban kezelhet matematikai objektum, de a robusztusságot növeljük.) További javítási lehetség, ha az eltéréseket nem az átlagtól hanem a mediántól vesszük, és nem is átlagoljuk ket, hanem a mediánjukat képezzük. A mutató neve, ami mindhárom ,,trükköt beveti: medián abszolút eltérés, jele \\(MAD\\), tehát \\[ MAD=\\mathrm{Me}\\left(\\left|x_i-\\mathrm{Me}\\left(x\\right)\\right|\\right). \\] (A szakirodalom itt nem teljesen egyértelm: néha \\(MAD\\)-nak nevezik azt a mutatót is, ahol csak az els javítást csinálják meg, tehát abszolútértéket vesznek, de azokat továbbra is csak átlagolják, és az eltéréseket is az átlagtól veszik.) A születési tömegek medián abszolút eltérése 563 gramm, tehát az újszülöttek testtömegeinek mediánjuk körül vett (abszolút) ingadozásának mediánja 563 gramm. 3.4.1.2.3 Alakmutatók A fenti két jellemzn túlmenen néha egyéb, még inkább részletekbe men jellemzit is használják egy változó leírásának. Egy tipikus példa erre a szimmetria: egy eloszlás szimmetrikus, ha a centrális tendencia helyétl mindkét irányban nagyjából hasonló a lefutása. (Vegyük észre, hogy ez nem következik még abból sem, ha két változóra ugyanaz a centrális tendencia, és ugyanaz a szóródás: ettl még az egyik lehet szimmetrikus, míg a másik nem.) A nem szimmetrikus eloszlásokat szokás ferde eloszlásoknak is nevezni; ezen belül is szoktak balra ferde (jobbra hosszan elnyúló) és jobbra ferde (balra hosszan elnyúló) eloszlásról beszélni, attól függen, hogy melyik irányban nagyobb a szóródás. További kérdések is felmerülnek, mint a csúcsosság, a multimodalitás stb.  ezekkel és a továbbiakkal azonban részletesen itt nem foglalkozunk. 3.4.2 Grafikus eszközök A grafikus eszközök közül elször a hisztogramot, utána röviden a magfüggvényes srségbecslt, majd végül a boxplotot tárgyaljuk meg. 3.4.2.1 Hisztogram A hisztogram leegyszersítve nem más, mint az osztályközös gyakorisági sor ábrázolása oszlopdiagramon, annyi specialitással, hogy az oszlopokat közvetlenül egymás mellé rajzoljuk, hely kihagyása nélkül (3.2. ábra). hist(birthwt$bwt, xlab = &quot;Születési tömeg [g]&quot;, ylab = &quot;Gyakoriság [f]&quot;, main = &quot;&quot;) rug(birthwt$bwt) Figure 3.2: Példa egy mennyiségi változó ábrázolására hisztogrammal. Az ábrán látható, hogy az oszlopok határai kijelölik az osztályközöket (ezek természetesen nem feltétlenül azonos szélességek); adott osztályköz fölé pedig \\[ \\frac{f_i}{n \\cdot h_i} \\] magasságú oszlopokat rajzolunk, ahol \\(h_i\\) az adott osztályköz szélessége. Ezen az ábrán feltüntettük (alul, apró tüskékként) magukat a nyers megfigyeléseket is (,,rugplot). A hisztogram a legnépszerbb adatvizualizációs módszer mennyiségi változókra. Ahogy már utaltunk is rá, hatalmas elnye, hogy a vizuálisan közölt információ rendkívül jól feldolgozható az emberi agy számára: a fenti hisztogram alapján szinte ,,ránézésre, egyetlen pillantással jó képünk alakul ki a centrális tendenciáról, a szóródásról, st, az eloszlás alakjának finomabb jellemzirl is. Egy átlagot még el sem olvastunk, amikorra a hisztogram alapján már olyan finom jellemzkrl, mint az eloszlás szimmetriája is képünk van. Hátránya, hogy kevésbé objektív (mint a grafikus módszerek általában)  ha például két változót össze kell hasonlítanunk, akkor két átlaggal (azaz két számmal) az értelemszeren könnyebben megtehet mint két hisztogrammal. A legnagyobb kihívás azonban az osztályközök helyes megválasztása. Ez a probléma teljesen ugyanaz, mint amit az osztályközös gyakorisági sornál is kifejtettünk. St, itt talán még jobban szemléltethet: a 3.3. ábrán ugyanazt az adatsort ábrázoltuk, csak épp az optimálisnál lényegesen több, illetve lényegesen kevesebb osztályközt használva is. par(mfrow = c(1, 3)) hist(birthwt$bwt, 3, xlab = &quot;Születési tömeg [g]&quot;, ylab = &quot;Gyakoriság&quot;, main = &quot;&quot;) hist(birthwt$bwt, xlab = &quot;Születési tömeg [g]&quot;, ylab = &quot;Gyakoriság&quot;, main = &quot;&quot;) hist(birthwt$bwt, 30, xlab = &quot;Születési tömeg [g]&quot;, ylab = &quot;Gyakoriság&quot;, main = &quot;&quot;) Figure 3.3: Ugyanazon adatsor ábrázolása különféle számú osztályközt tartalmazó hisztogrammal. Itt érzékelhet igazán, hogy miért probléma az is, ha túl finom, és az is, ha túl durva felosztást választunk (adott, rögzített mintanagyság mellett!). Amennyiben az osztályközök száma túl kevés, akkor sok információt vesztünk: az eloszlásról kapott kép összemossa a finomabb részleteket (bal oldal). Úgy is szokták mondani: nagy lesz a torzítás. Ha viszont túl sok osztályközt választunk, akkor rendkívül esetlegessé válik, hogy egy osztályközbe hány mintaelem esik, nagyon ingadozó lesz a magasság (jobb oldal), úgy szokták mondani: nagy lesz a variancia. (Ez itt a sok más helyen is megjelen torzítás-variancia trade-off egy példája.) Ahogy sokszor elmondtuk: valamiféle optimumot kell találni a kett között. Ennek módszereirl az osztályközös gyakorisági sornál már írtunk. Az osztályközöket többféleképp is megadhatjuk R-ben: Explicite megadjuk az osztályközök határait: hist( birthwt$bwt, breaks = c( 500, 1500, 2000, 2500, 2750, 3000, 3250, 3500, 5000 ) ). Megadjuk az osztályközök számát: hist( birthwt$bwt, breaks = 10 ). Megadjuk a szabály nevét, amivel kérjük az osztályközök számának kiszámolását: hist( birthwt$bwt, breaks = \"Sturges\" ). Saját függvényt adunk meg, mely vagy az osztályközök számát, vagy a határait kiszámolja az adatok alapján. 3.4.2.2 Magfüggvényes srségbecsl A hisztogrammal kapcsolatos egyik probléma az elbb említett érzékenység az osztályközök megválasztására. Emellett felvethet az is, hogy a hisztogram szakaszonként konstans becslést ad, ami zavaró lehet (különösen, ha kicsi a mintanagyság, és emiatt nem tudunk sok osztályközt felvenni). Ez utóbbit kiküszöböli, és sok gyakorlati esetben az elbbit is enyhíti a magfüggvényes srségbecsl alkalmazása. Ennek matematikai részleteivel most nem foglalkozunk, megelégszünk annyival, hogy a hisztogramhoz hasonlóan az eloszlás alakját becsli, ám a hisztogramtól eltéren nem szakaszonként konstans görbével (3.4. ábra). plot(density(birthwt$bwt), xlab = &quot;Születési tömeg [g]&quot;, ylab = &quot;Srség&quot;, main = &quot;&quot;) Figure 3.4: Példa egy mennyiségi változó ábrázolására magfüggvényes srségbecslvel. Sajnos az osztályközök megválasztásának problémája teljesen nem oldódik meg, a magfüggvényes srségbecslnek is van ugyanis állítható paramétere (magfüggvény, és különösen az ún. sávszélesség). Ennek optimális megválasztása szintén probléma lehet, különösen, ha nagyon egyenetlen a mintaelemek eloszlása. 3.4.2.3 (Tukey-féle) boxplot Végül egy egész más elven felépül, de szellemes, és a gyakorlatban is nagyon hasznos vizualizációs módszerrel ismerkedünk meg, a (Tukey-féle) (vagy ritkán használt magyar nevén: dobozábrával). A boxplot nem más, mint egy számegyenes fölé rajzolt téglalap, mely egy adott változót reprezentál úgy, hogy a téglalap alsó széle az alsó kvartilisnél (\\(Q_1\\)-nél), a fels széle pedig a fels kvartilisnél (\\(Q_3\\)-nál) van. A téglalapon belül egy vastagabb függleges vonal is látható, ez a mediánnál található (3.5. ábra). boxplot(birthwt$bwt) Figure 3.5: Példa egy mennyiségi változó ábrázolására boxplottal. A boxplotból két ,,antenna nyúlik ki felfelé és lefelé. A boxplot alapváltozatában ezek a mintaminimumig és mintamaximumig nyúlnak ki, de a némileg haladóbb megvalósításban (amit a fenti ábra is mutat) az alsó antenna nem a minimumig terjed, hanem a legkisebb elemig, ami nem kisebb, mint \\(\\mathrm{Me}-\\alpha \\cdot IQR\\); hasonlóképp a fels antenna nem a maximumig terjed, hanem a legnagyobb elemig, ami nem nagyobb mint \\(\\mathrm{Me}+\\alpha \\cdot IQR\\). (\\(\\alpha\\) egy elre megadott konstans, tipikusan \\(\\alpha=1,\\!5\\).) Azokat az elemeket melyek ezen kívül helyezkednek el, külön szimbólum, például kis karika jelöli. E mögött az a megfontolás, hogy így a boxplot egyszer outlier-szrést is lehetvé tesz: azok az elemek minsülnek outliernek, melyek az antennákon kívül helyezkednek el. A boxplot jóval nagyobb információtömörítést hajt végre mint akár a hisztogram, akár a magfüggvényes becsl  ez részint hátránya, bár ennek ellenére gyakorlott szem számára így is meglehetsen jó információt hordoz az eloszlás alakjáról. Azonban ugyanez elnye is, hiszen kompakt (ami különösen jól jön akkor, ha például több csoportot kell összehasonlítani), valamint további nagy elnye, hogy  szemben mind a hisztogrammal, mind a magfüggvényes becslvel  semmilyen paraméter hangolását nem igényli, így kinézete teljesen egyértelmen meghatározott. 3.5 Minségi változók kétváltozós elemzése Minségi változók kapcsolatát asszociációnak szokás nevezni a statisztikában. Erre jó példa adatbázisunk rassz (race) és irritábilis méh (ui) változói, mely az alany rassz szerinti hovatartozását és az irritábilis méh szindróma fennállását adja meg. 3.5.1 Analitikus eszközök Ahogy már megbeszéltük, a kétváltozós vizsgálatok sava-borsa az lesz, hogy a változók kapcsolatáról is képesek leszünk nyilatkozni. Ahhoz, hogy precízen definiáljuk, hogy mit értünk kapcsolat alatt, elsként bemutatjuk az kontingenciatáblát (vagy kombinációs táblát vagy kereszttáblát), mely egyúttal az egyik legfontosabb analitikus eszköz is lesz két minségi változó kapcsolatának vizsgálatában. Ezt követen nagyon röviden beszélünk a kapcsolat jellemzésére használható mutatószámokról is. 3.5.1.1 Kontingenciatábla A kontingenciatábla egy olyan táblázat, melynek soraiban és oszlopaiban a két változó lehetséges kimenetelei vannak, az egyes cellákban pedig azon megfigyelési egységek darabszáma (tehát gyakorisága), melyek a cella sora és oszlopa szerinti kimenetek a sorhoz illetve az oszlophoz rendelt változó szerint. Például, a rassz és az irritábilis méh kontingenciatáblája így néz ki: table(birthwt$race, birthwt$ui) ## ## 0 1 ## Kaukázusi 83 13 ## Afroamerikai 23 3 ## Egyéb 55 12 Tehát például 83 olyan megfigyelési egység van az adatbázisban, ahol az anya rassza kaukázusi és nincs irritábilis méh szindrómája 12 egyéb rasszú, és irritábilis méh szindrómában szenved alany van, és így tovább. A kontingenciatábla szigorúan véve csak a \\(3 \\times 2\\) darab gyakoriságot jelenti; de néha összegz sorokat vagy oszlopokat írunk mellé: tab &lt;- table(birthwt$race, birthwt$ui) rbind(cbind(tab, margin.table(tab, 1)), cbind(t(margin.table(tab, 2)), margin.table(tab))) ## 0 1 ## Kaukázusi 83 13 96 ## Afroamerikai 23 3 26 ## Egyéb 55 12 67 ## 161 28 189 Ezek neve: perem- vagy vetületi gyakoriság. (Mindkét elnevezés logikus: perem, hiszen a kontingenciatábla peremére kell ezeket ráírni, és vetületi, hiszen úgy kaphatjuk, hogy a kontingenciatáblát levetítjük vízszintesen vagy függlegesen ,,levetítjük, vetítés alatt most azt értve, hogy az egymásra ,,vetül elemeket összeadjuk.) A 189 a mintanagyság. A fenti gyakoriságokon túl természetesen relatív gyakoriságokról is beszélhetünk. A relatív gyakoriság definícióját közvetlenül alkalmazva kapjuk azt a lehetséget, hogy mindegyik cellát leosztjuk a mintanagysággal, például a bal fels \\(83/189=43,\\!9\\)% lesz. Ez az irritábilis méh szindrómában szenved kaukázusiak aránya a teljes mintán belül. A relatív gyakoriságokkal kitöltött kontingenciatábla peremei a relatív peremgyakoriságok (vagy relatív vetületi gyakoriságok). Szokás ezt peremmegoszlásnak vagy vetületi megoszlásnak is nevezni. (Az elnevezés nem meglep: már korábban is utaltunk rá, hogy egy teljes relatív gyakorisági sort a statisztikusok általában megoszlásnak neveznek.) Kontingenciatábla esetén azonban van egy másik  logikus  mód arra, hogy relatív gyakoriságot értelmezzünk: a 43,9% megadja, hogy az összes alany mekkora hányada kaukázusi irritábilis méh szindrómában nem szenved, de minket érdekelhet az is, hogy az (összes helyett) csak az irritábilis méh szindrómában nem szenvedk mekkora hányada kaukázusi. Azaz: a 83-at nem a 189-cel, hanem a 161-gyel osztjuk le: \\(83/161=51,\\!6\\)%. Ezt nevezzük feltételes relatív gyakoriságnak. Azért feltételes, mert ez egy relatív gyakoriság azon feltétel mellett, hogy valaki nem szenved irritábilis méh szindrómában. Más szóval: ha feltesszük, hogy az alanyaink nem szenvednek irritábilis méh szindrómában akkor közöttük 51,6% a kaukázusiak aránya. Ez természetesen kiszámolható a rassz változó másik két kimenetére is; az így kapott 51,6%14,3%34,2% egy teljes (csak épp feltételes) relatív gyakorisági sor, összege nyilván 100%. Szokás ezt a sorváltozó (esetünkben a rassz) feltételes megoszlásának is nevezni, az a oszlopváltozó (esetünkben az irritábilis méh) adott értéke (esetünkben: igen) mint feltétel mellett. Természetesen ugyanezek kiszámolhatóak a jobb oldali oszlopra is, ez magyarul azt jelenti, hogy az irritábilis méh nem kimenetére feltételezünk. Az eljárás ugyanez, azzal a különbséggel, hogy a jobb oldali számokat nyilván 28-cal kell leosztani. A feltételes relatív gyakoriság tehát nem más, mint a gyakoriság adott peremgyakorisággal osztva. Természetesen nem csak az oszlopváltozóra feltételezhetünk! Pontosan ugyanígy van értelme beszélni az oszlopváltozó feltételes eloszlásáról a sorváltozó adott értéke, mint feltétel mellett. Például kijelenthetjük, hogy annak feltételes relatív gyakorisága, hogy egy alany nem szenved irritábilis méh szindrómában \\(83/96=86,\\!5\\)% azon feltétel mellett, hogy kaukázusi a rassza. Hasonlóan továbbmenve azt is mondhatjuk, hogy az irritábilis méh fennállásának feltételes megoszlása azon feltétel mellett, hogy az alany kaukázusi, 86,5%13,5%. Összefoglalva, egy cellához négyféle számot is rendelhetünk, a bal fels példáján: 83 (gyakoriság), 43,9% (relatív gyakoriság), 51,6% (feltételes relatív gyakoriság azon feltétel mellett, hogy nem áll fenn irritábilis méh szindróma) és 86,5% (feltételes relatív gyakoriság azon feltétel mellett, hogy a rassz kaukázusi). Mindezeket szemléltetik a következ táblázatok. Relatív gyakoriságok (peremeken a vetületi megoszlásokkal): tab &lt;- prop.table(table(birthwt$race, birthwt$ui)) rbind(cbind(tab, margin.table(tab, 1)), cbind(t(margin.table(tab, 2)), margin.table(tab))) ## 0 1 ## Kaukázusi 0.4 0.07 0.5 ## Afroamerikai 0.1 0.02 0.1 ## Egyéb 0.3 0.06 0.4 ## 0.9 0.15 1.0 Irritábilis méh feltételes relatív gyakoriságai a rassz különböz kimenetei, mint feltétel esetén tab &lt;- prop.table(table(birthwt$race, birthwt$ui), 1) rbind(cbind(tab, margin.table(tab, 1))) ## 0 1 ## Kaukázusi 0.9 0.1 1 ## Afroamerikai 0.9 0.1 1 ## Egyéb 0.8 0.2 1 Rassz feltételes relatív gyakoriságai az irritábilis méh különböz kimenetei, mint feltétel esetén: tab &lt;- prop.table(table(birthwt$race, birthwt$ui), 2) rbind(tab, t(margin.table(tab, 2))) ## 0 1 ## Kaukázusi 0.5 0.5 ## Afroamerikai 0.1 0.1 ## Egyéb 0.3 0.4 ## 1.0 1.0 Természetesen nem arról van szó, hogy bármelyik jobb lenne, mint a többi  egyszeren más elemzési célra alkalmasak. A feltételes megoszlásokra gondolva, az is érdekes kérdés lehet, hogy a kaukázusiak mekkora hányada szenved irritábilis méh szindrómában, és az is érdekes (de más tartalmú) kérdés, hogy az irritábilis méh szindrómában szenvedk mekkora hányada kaukázusi rasszú. Mindezek között egyszer algebrai összefüggések állnak fenn, ezeket most nem részletezzük. Továbbhaladva, tökéletesen látható, hogy miért mondtuk, hogy a többváltozós elemzés az egyváltozós elemzések kiterjesztése: a fenti kétdimenziós kontingenciatáblában minden információ benne van, amit a két változót külön-külön elemezve látnánk: egyszeren levetítjük a kontingenciatáblát a megfelel dimenziós mentén és kapott vetületi gyakoriságok nem mások lesznek, mint a vetítési irány változójának gyakorisági sora! (Amiben minden információ benne van.) Az tehát egyértelm, hogy ez tartalmazza mindazt az információt, amit a két változó külön-külön végzett vizsgálata  csakhogy mi azt állítottuk, hogy többet is. Ez vezet el a változók kapcsolatának kérdéséhez. Minségi változók esetében (kontingenciatáblán) akkor mondjuk, hogy két változó kapcsolatban van egymással, ha a sorváltozó feltételes megoszlásai ugyanazok, az oszlopváltozó bármely értékére is feltételezünk. Vagy  ami ezzel egyenérték : az oszlopváltozó feltételes megoszlásai ugyanazok, a sorváltozó bármely értékére is feltételezünk. (Ez els ránézésre, kicsit nagyvonalú volt, de belátható matematikailag, hogy a kett valóban egyenérték: ha az oszlopváltozó feltételes megoszlásai ugyanazok minden sorban, akkor a sorváltozó feltételes megoszlásai is ugyanazok minden oszlopban, és fordítva is, ha az oszlopváltozó feltételes megoszlásai nem ugyanazok minden sorban, akkor a sorváltozó feltételes megoszlásai sem ugyanazok minden oszlopban.) Ez a definíció jogos: általánosságban véve is, az, hogy két változó között nincs kapcsolat, azt jelenti statisztikai nyelven, hogy az egyikre vonatkozó információból nem nyerünk információt a másikra vonatkozóan. Így már érthet ez a kontingenciatáblákra alkalmazott definíció: ha nincs kapcsolat, akkor hiába mondjak meg valaki, hogy mi  például  a sorváltozó értéke, ebbl semmit nem tudunk meg az oszlopváltozó feltételes megoszlásáról (hiszen az minden sorban ugyanaz!). Ha van kapcsolat, akkor nyerünk plusz-információt (hiszen más lesz a feltételes megoszlása). Látható, hogy ebben az esetben csak nagyon gyenge kapcsolatról beszélhetünk: a sorváltozó feltételes megoszlása mindkét oszlopban (precízen: az oszlopváltozó mindkét kimenetére feltételezve) nagyjából ugyanaz (kb. 50%kb. 10%kb. 40%), és az oszlopváltozó feltételes megoszlása is nagyjából ugyanaz mindhárom sorban (kb. 85%kb. 15%). Ahogy már elmondtuk, az elbbi mondat bármelyik felébl automatikusan következik a másik fele. Itt tehát szemléletesen is látható a kapcsolat hiányának tartalma: hiába is mondja meg valaki, hogy az alany rassza kaukázusi, afroamerikai vagy egyéb, szinte ugyanúgy csak azt tudjuk mondani, hogy ,,akkor 85%15% a megoszlás az irritábilis méh fennállása szerint. A rasszra vonatkozó információ nem adott szinte semmilyen információt a másik változóról. Képzeljünk el ezzel szemben  másik végletként  egy olyan esetet, melyben a 189 alany közül 100 kaukázusi irritábilis méh szindróma nélkül, és 89 egyéb rasszú irritábilis méh szindrómával! Ebben az esetben az egyik változóra vonatkozó információ nem egyszeren ,,elárul valamit a másik változóról, hanem egyenesen determinálja azt: ha valaki elárulja, hogy egy alany kaukázusi rasszú, akkor biztosan tudjuk, hogy nem szenved irritábilis bél szindrómában, ha pedig azt mondja, hogy egyéb rasszú, akkor rögtön tudjuk, hogy szenved ebben. (Természetesen itt is igaz, hogy a dolog fordítva is mködik: ha tudjuk, hogy egy alany nem szenved irritábilis méh szindrómában, akkor azonnal tudjuk, hogy kaukázusi, ha pedig nem szenved ebben, akkor biztos, hogy egyéb rasszú.) Ez a kapcsolat másik végpontja. Zárásként megjegyezzük, hogy a statisztikában valójában nem így szokták bevezetni a kapcsolat fogalmát, hanem úgy, mint azt az esetet, amikor a két változó nem független egymástól; függetlenség alatt pedig azt értik, hogy az együttes megoszlás a vetületi megoszlások szorzataként áll el. Érdemes végiggondolni, hogy ez valóban egybeesik a hétköznapi ,,függetlenség fogalommal. Szintén érdemes végiggondolni, hogy ebbl valóban következik a fenti definíció, de ezzel részletesebben nem foglalkozunk most. 3.5.1.2 Mutatószámok A kapcsolat ersségének kvalitatív fogalmát fent megadtuk; erre több mutatót is definiáltak, melyekkel az ersség számszeren is lemérhet. Amennyiben a változók nominálisak, úgy pusztán erre van lehetség. Ha azonban a változók ordinálisak, úgy értelmet nyert a kapcsolat irányának fogalma is. Ordinális változók esetén ugyanis a sorok és oszlopok sorrendje nem tetszleges, van értelme mindkét változó szerint ,,nagyobb és ,,kisebb kimenetrl beszélni. Innentl kezdve tehát nem csak azt mondhatjuk, hogy van kapcsolat, ha más oszlopban más a feltételes megoszlás, hanem értelmet nyer az a kijelentés is, hogy nagyobb oszlopban a feltételes megoszlás úgy más, hogy inkább nagyobb sorbeli érték szerepelnek, vagy épp úgy, hogy inkább kisebbek. (Itt is egyenérték, ha ugyanezt a sorok és oszlopok fordított szerepével mondjuk el.) Ezt ragadja meg a kapcsolat irányának fogalma: ha van kapcsolat (nem 0 az erssége), akkor az pozitív, amennyiben az oszlopváltozó szerinti nagyobb érték tendenciájában a sorváltozó szerinti nagyobb értékkel jár együtt (és fordítva), negatív, ha az oszlopváltozó szerinti nagyobb érték tendenciájában a sorváltozó szerint kisebb értékkel jár együtt (és fordítva). Ordinális változónál errl is lehet nyilatkozni mutatókkal. A konkrét mutatószámokkal most nem foglalkozunk (többek között azért sem, mert meglehetsen sok van bellük, attól függen, hogy pontosan hogyan viselkednek az egyes változók). 3.5.2 Grafikus eszközök Kontingenciatáblát vizualizálni ún. mozaikábrával és asszociációs ábrával lehet, ezek azonban nem túl látványos, és emiatt nem is túl gyakran használt módszerek, így most mi sem részletezzük ezeket. Ami bevettebb, az a vetületi megoszlások (vagy nevezetes feltételes megoszlások) ábrázolása egyszeren oszlopdiagramon (vagy kördiagramon), ez azonban jól láthatóan ugyanaz a feladat, amit már minségi változók egyváltozós elemzésénél megbeszéltünk. 3.6 Mennyiségi változók kétváltozós elemzése Mennyiségi változók kapcsolatát korrelációnak szokás nevezni a statisztikában. Erre jó példa adatbázisunk anyai testtömeg (lwt) és újszülött születési tömege (bwt) változói, melyek az anya illetve az újszülött testtömegét tartalmazzák. 3.6.1 Analitikus eszközök A kapcsolat fogalmát mennyiségi változókra is ugyanazon gondolatot követve értelmezzük, mint amit minségi változóknál már láttunk. Azt mondjuk, hogy két változó kapcsolatban van egymással, ha az egyik változó átlag feletti értékei tendenciájában a másik változó átlag feletti értékeivel járnak együtt (és ekkor persze fordítva is: az egyik változó átlag alatti értékei tendenciájában a másik változó átlag alatti értékeivel járnak együtt). Azaz: ha egy megfigyelési egység értéke az egyik változó szerint átlag feletti, akkor várhatóan a másik változó szerint is átlag feletti lesz. Pontosabban szólva ez a pozitív kapcsolat definíciója, a negatív esetén az egyik változó átlag feletti értékei tendenciájában a másik átlag alatti értékeivel járnak együtt, és fordítva. Itt természetesen sztochasztikus kapcsolatról beszélünk, ezért a ,,tendenciájában kifejezés: nem arról van szó, hogy ha a megfigyelési egység egyik változója átlag feletti, akkor _biztos, hogy a másik is, de az esetek többségében érvényesül ez a tendencia. Érdemes megfigyelni, hogy itt mindenképp van értelme az iránynak (összhangban azzal, hogy a mennyiségi változók bírnak az ordinális tulajdonságaival is, természetesen). Két mennyiségi változó fent definiált kapcsolatát klasszikusan a kovarianciával szokás lemérni. Ennek definíciója: \\[ \\mathrm{cov}\\left(x,y\\right)=\\frac{\\sum_{i=1}^n \\left[\\left(x_i-\\overline{x}\\right)\\left(y_i-\\overline{y}\\right)\\right]}{n}. \\] A számítás logikája vegytisztán tükrözi a definíciót: az \\(\\left(x_i-\\overline{x}\\right)\\) tükrözi az egyik, az \\(\\left(y_i-\\overline{y}\\right)\\) a másik változó szerint azt, hogy az adott megfigyelési egység átlag alatti vagy átlag feletti. Vegyük észre, hogy a kett szorzata pedig pontosan akkor lesz pozitív, ha vagy mindkét változó szerint átlag feletti a megfigyelési egység, vagy mindkét változó szerint átlag alatti  azaz ha az adott megfigyelési egység a pozitív kapcsolatot ersíti meg! Ha a szorzat negatív, akkor az adott megfigyelési egység a negatív kapcsolatot ersíti. St, ennél több is igaz: a szorzatnak nem csak az eljele stimmel, de a nagysága is, az ugyanis kifejezi, hogy mennyire ersít meg bennünket az adott megfigyelési egység a kapcsolat fennállásában. Ha a megfigyelési egység egyik (pláne ha mindkét) változó szerint közel van az átlaghoz, akkor az csak gyenge ,,bizonyíték a kapcsolat mellett (kis módosulással lehet, hogy az ellenkez irányú kapcsolatot ersítené), viszont ha mindkét változó szerint távol van az átlagtól, az ers érv a kapcsolat mellett. A szummázás ezeket a hatásokat fogja összeadni megfigyelési egységrl megfigyelési egységre, így eljele a kapcsolat irányát mutatja, abszolút értéke pedig annak ersségét. (Az \\(n\\)-nel való leosztás nyilván szükséges, különben a kétszer megismételt adatbázison kétszer akkora lenne a kovariancia, holott az információ ugyanaz; tehát ezeket a szorzatokat átlagolni kell.) Hogy mi a kovariancia problémája, az azonnal kiderül, ha közöljük az anyai és az újszülött testtömeg közti kovarianciát: 4141.7. Ami kétségtelenül kiolvasható ebbl, hogy az anyai és az újszülött testtömeg között van kapcsolat, mégpedig pozitív irányú (nagyobb anyai tömeg  nagyobb újszülött tömeg, és fordítva), hiszen az eljel pozitív. Amirl viszont lényegében semmit nem tudunk meg, az az ersség! Annál is inkább, mert a kovariancia mértékegység-függ: más értéket kapunk, ha az újszülött testtömegét nem grammban, hanem kilogrammban rögzítjük. Tekintetbe véve, hogy az információ ettl még ugyanaz marad, ez nyilván nem szerencsés A probléma tehát, hogy honnan tudhatnánk, hogy a 4141.7 sok vagy kevés? Ebben segít minket az a matematikai észrevétel, hogy mindenképp fennáll a \\(-s_x s_y \\leq \\mathrm{cov}\\left(x,y\\right) \\leq s_x s_y\\) összefüggés, tehát a kovariancia abszolút értéke nem lehet nagyobb mint a két változó szórásának szorzata. Így máris van mihez viszonyítani a kovariancia nagyságát! Ez tehát a következ mutató definiálását adja, a neve korrelációs együttható: \\[ \\mathrm{corr}\\left(x,y\\right)=\\frac{\\mathrm{cov}\\left(x,y\\right)}{s_x s_y}. \\] Ez az eljel értelmezésén semmit nem változtat, hiszen a kovariancia eljelét meghagyja (a nevezben szórások szerepelnek, így mindkett szükségképp pozitív), viszont az abszolút értéket értelmezhetvé teszi, hiszen a korrelációra már az teljesül, hogy \\(-1 \\leq \\mathrm{corr}\\left(x,y\\right) \\leq 1\\). A korreláció tehát minél közelebb van \\(\\pm 1\\)-hez, annál ersebb a két változó közötti kapcsolat. Például, az anyai testtömeg és az újszülött születési tömege közti korrelációs együttható értéke 0.2. Ez alapján nem csak azt tudjuk mondani, hogy van kapcsolat és az pozitív irányú (a 0.2 eljele pozitív), de most már azt is, hogy ez a kapcsolat igen gyenge (ha elhelyezzük a 0.2-ot a 01 között). Belátható, hogy az így definiált korrelációs együttható a lineáris kapcsolat ersségét méri (szokás emiatt lineáris korrelációs együtthatónak is nevezni). Valóban, ha a korreláció abszolút érték 1, az épp azt jelenti, hogy \\(y=ax+b\\) függvényszer kapcsolat van a két változó között. De általában is, a korreláció ,,ersségét úgy kell érteni, hogy mennyire szorosan valósul meg ez az egyenesre illeszkedés. Fontos megjegyezni, hogy más kapcsolat ersségét nem méri ez az együttható, tehát nem lineáris kapcsolat lehet a két változó között (extrém esetben akár függvényszer is!), úgy, hogy közben a lineáris korrelációs együttható értéke nulla. Erre tekintettel szokás más korrelációs együtthatókat is definiálni, ezek közül megemlítjük a Spearman-\\(\\rho\\) és a Kendall-\\(\\tau\\) mutatókat, ezek ún. rangkorrelációs mutatók, amik nem konkrétan lineáris, hanem általános monoton kapcsolat ersségét mérik. Nem foglalkozunk vele részletesen, de megemlítjük, hogy itt is igaz, hogy a kapcsolat erssége azzal van összefüggésben, hogy az egyik változó ismerete mennyi információt árul el a másik változóról (természetesen sztochasztikus értelemben). Végül egy figyelmeztetés. Mint általában, természetesen itt is elmondható, hogy a mutatószám használata nagyon nagy információtömörítést jelent. Éppen ezért ne támaszkodjunk önmagában egy korrelációs együtthatóra (és különösen ne önmagában egy lineáris korrelációs együtthatóra) két változó kapcsolatának megítéléséhez, hiszen ez elfedi az esetleges nemlineáris kapcsolatokat, az outliereket stb. Erre egy nevezetes példa az Anscombe-kvartett, amit mi is hamarosan bemutatunk. 3.6.2 Grafikus eszközök Két mennyiségi változó kapcsolatának legfontosabb ábrázolási eszköze az szóródási diagram. A szóródási diagramot úgy kapjuk, hogy minden megfigyelési egységnek egy pontot feleltetünk meg a síkban úgy, hogy a pont egyik koordinátája a megfigyelési egység egyik, a másik koordinátája a másik változó szerinti értéke. (Tehát lényegében a megfigyelési egységhez tartozó változókat koordinátáknak tekintjük, és ezeket mérjük fel egy kétdimenziós koordináta-rendszer két tengelyére.) Az anyai és újszülött testtömeg szóródási diagramját a 3.6. ábra mutatja. plot(bwt ~ lwt, data = birthwt, xlab = &quot;Anya testtömege (UM) [font]&quot;, ylab = &quot;Születési tömeg [g]&quot;) abline(h = mean(birthwt$bwt), v = mean(birthwt$lwt), lty = &quot;dashed&quot;) abline(lm(bwt ~ lwt, data = birthwt), lty = &quot;dotted&quot;) Figure 3.6: Két mennyiségi változó kapcsolatának ábrázolása szóródási diagrammal. Az ábrán bejelöltük (szaggatott vonallal, a két tengellyel párhuzamosan) a két változó átlagát is. Jól látható, immár grafikusan is, hogy mit értünk a két változó közötti kapcsolat fogalmán: a pontok tendenciájukban a szaggatott vonalak által kijelölt koordináta-rendszer jobb fels és bal alsó kvadránsában találhatóak (átlag feletti  átlag feletti és átlag alatti  átlag alatti zónák). Természetesen látszik az is, hogy a kapcsolat sztochasztikus, azaz van pont a több kvadránsban is (itt aztán pláne, hiszen a kapcsolat nem is túl ers). Ne feledjük azt sem, hogy nem csak a pontok darabszáma számít, hanem a konkrét helyzetük is (mennyire ,,ersíti meg a kapcsolat fennállását). Ráersítve az elbb mondottakra, az ábrán behúztuk a pontokra legjobban illeszked egyenest is. Ahogy említettük, a kapcsolat ,,erssége egyúttal azt is jelenti, hogy a pontok mennyire szorosan illeszkednek a rájuk legjobban illeszked egyenesre (látható, hogy itt nem túl szorosan). Mindezeket szemlélteti a 3.7. ábra is, mely különböz korrelációs együtthatójú kapcsolatokat (különböz eljelekkel és abszolút értékekkel, azaz különböz irányú és ersség kapcsolatokat) mutat be példákkal. Figure 3.7: Különféle korrelációs együtthatók szemléltetése. A grafikus ábrázolás elnye, hogy (szemben a korrelációs együtthatóval) nem okoz gondot semmilyen outlier, nemlineáris kapcsolat stb.  ezek mind láthatóak lesznek az ábrán. (Itt is hangsúlyosan él tehát Tukey már említett tanácsa) Erre mutat példát a nevezetes Anscombe-kvartett (3.8. ábra). Az ábrák négy kétváltozós adatsor szóródási diagramját mutatják. Mindegyiknek hajszálpontosan ugyanaz a korrelációs együtthatója (st, az átlaguk és a szórásuk is  így ugyanaz a rájuk legjobban illeszked egyenes is), mégis, a valós helyzet drámaian más. Outlierek, nemlineáris kapcsolatok vannak jelen. Ez azonban csak ábrázolás után derül ki, a korrelációs együttható használata mindezt teljesen elfedné! Figure 3.8: Az Anscombe-kvartett. Zárásként megjegyezzük, hogy ebben a grafikus ábrázolásban valóban nincsen semmilyen információtömörítés. Az is igaz, hogy a kétváltozós elemzés tartalmaz minden információt, amit a két egyváltozós elemzés: a pontokat levetítve valamelyik tengelyre, visszakapjuk az adott tengely változójának adatait; azokat csoportosítva (a tengelyt osztályközökre bontva) rögtön készíthet például hisztogram. Szemléletesen látszik azonban az is, hogy pusztán a hisztogramokból (tehát az egyváltozós adatokból) lehetetlen lenne nyilatkozni a két változó közti kapcsolatról. (Képzeljünk egy egy olyan esetet, melyben a változók között ers kapcsolat van, de úgy, hogy mindkét változó önmagában szimmetrikus. Ekkor nyugodtan tükrözhetnénk a szóródási diagramot bármelyik átlagot jelent szaggatott vonalra, az egyváltozós adatok ugyanazok maradnának, noha kétváltozósan pont hogy megfordult a kapcsolat iránya.) Ezért több a kétváltozós elemzés mint két egyváltozós elemzés. 3.7 További többváltozós elemzések A kétváltozós esetek tárgyalásából a fentiekben kimaradt az az eset, amikor egy minségi és egy mennyiségi változó kapcsolatát kell vizsgálni. Ezt vegyes kapcsolatnak szokás nevezni; részletesebben most nem foglalkozunk vele. A másik kérdés, ami felmerül, hogy mi a helyzet kettnél több változó esetén. Ha nem lényegesen több változóról van szó, akkor a fenti módszerek  több-kevesebb módosítással  de kiterjeszthetek. Például a szóródási diagram elvileg három változós esetre változatlanul kiterjeszthet (bár a gyakorlatban már ezt sem nagyon szokták használni, hiszen egy három dimenziós pontfelh csak számítógépen tekinthet meg érdemben, és ott se túl áttekinthet emberi szemnek). Négy és annál több dimenziónál már trükkre van szükség; a tipikus megoldás, hogy minden lehetséges koordináta-párra levetítik a sokdimenziós pontfelht, és az így kapott kétdimenziós szóródási diagramokat mutatják meg (mátrix szóródási diagram). Egy-két tucat változó felett azonban már ez sem igazán tekinthet át, illetleg már nem nevezhet érdemben kettnél több dimenziós elemzésnek. Hasonló a helyzet a korrelációs együtthatóval, illetve a kontingenciatáblával és elemzési eszközeivel. "],["induktiv.html", "4 . fejezet Induktív statisztika 4.1 A mintavételi helyzet és következményei 4.2 Becsléselmélet 4.3 Hipotézisvizsgálat", " 4 . fejezet Induktív statisztika Ebben az alfejezetben röviden, az alapkoncepciókra fókuszálva bemutatjuk a statisztika induktív ágát. Már volt róla szó, hogy az induktív statisztika jellemzje, hogy tekintettel van a mintavételi helyzetre (azaz arra, hogy mi csak egy részét ismerjük azon sokaságnak, melyre a kérdésünk irányult): azzal foglalkozik, hogy hogyan lehet pusztán a mintában lév információ alapján mégis a sokaságról nyilatkozni. Innen a módszer neve: indukció a.m. következtetés, tudniillik következtetés a mintából a sokaságra. Elsként röviden megismételjük, és pár fontos részlettel kibvítjük a mintavételi helyzettel kapcsolatos ismereteinket; ezt követen nagyon tömören, az alapelvekre szorítkozva bemutatjuk az induktív statisztika két nagy területét: a becsléselméletet és a hipotézisvizsgálatot. A becsléselmélet azzal foglalkozik, hogy egy sokaságot jellemz paramétert, például a sokaság átlagát pusztán a minta alapján ,,megtippeljünk (valamilyen szempontok szerint a lehet legjobban). A hipotézisvizsgálat ennek bizonyos értelemben az ikertestvére: célja, hogy a sokaság valamely jellemzjére tett állítások  például a sokaság átlaga egy adott szám  helyességét ,,megtippeljük pusztán a minta alapján. 4.1 A mintavételi helyzet és következményei Ahogy már megbeszéltük, mintavételi helyzetrl akkor beszélünk, ha a sokaságnak (amire, definíció szerint, kutatási kérdésünk vonatkozik), csak egy részét tudjuk megfigyelni. Ezt a megfigyelt részt nevezzük mintának. Szintén volt róla szó, hogy a mintavételi helyzet jelentsége a biostatisztikában hatalmas: nem csak azért, mert egy sor gyakorlati esetben bár a sokaság elvileg teljeskören megfigyelhet lenne, de erre gyakorlati okok (költség, idigény stb.) miatt nincs mód, hanem azért is, mert biostatisztikában tipikusak az olyan kérdések, melyek fiktív, végtelen sokaságra vonatkoznak (például: ,,Egy új vérnyomáscsökkent gyógyszer-jelölt valóban csökkenti a vérnyomást?). Ilyen esetekben bármennyi megfigyelést is végzünk, az szükségképp minta lesz. Adódik tehát a feladat, hogy annak ellenére nyilatkozzunk a sokaságról, hogy mi csak egy részét ismerjük. Nagyon sokan ezen a ponton valószínleg azt gondolják, hogy ez lehetetlen feladat  valóban, példának okáért, ha 1000 elembl csak 999-et ismerünk, akkor elvileg bármennyi lehet a sokaság (mind az 1000 elem) átlaga, akármik is voltak a minta elemei. Az a megállapítás azonban, hogy ,,semmit nem tudunk mondani a sokaságról, szerencsére túlzás. A helyes megfogalmazás az, hogy biztosat nem tudunk mondani a sokaságról de valószínségi kijelentéseket továbbra is tudunk tenni! Ha ugyanis megfelelen történt a mintavétel (erre még visszatérünk), akkor már a minta is elárult valamit a sokaságról, tudni fogunk valamit azokról a valószínségi törvényszerségekrl, melyek az ismeretlen elemek viselkedését (is) áthatják. Ez pedig lehetvé fogja tenni, hogy ugyan csak sztochasztikus értelemben, de azokról is nyilatkozzunk. Az tehát nem igaz, hogy semmit nem tudunk mondani a sokaságról, de azzal valóban együtt kell élnünk, hogy az induktív statisztikában  szemben a deskriptívvel  már csak bizonytalansággal terhelt állításokat tudunk tenni. Szerencsére azonban arra is képesek leszünk, hogy e bizonytalanság mértékét magát is becsüljük (persze ismét csak: bizonytalansággal terhelten). Nyilvánvaló, hogy bármilyen induktív statisztikai feladatot is kell megoldanunk, ahhoz csak a mintában lév információt tudjuk felhasználni (ez épp a minta definíciója). Márpedig ha csak a sokaság egy részét (a mintát) ismerjük, akkor bármilyen, mintából számolt jellemz két dologtól fog függeni: a jellemz sokaságbeli értékétl, attól, hogy konkrétan hogy választottuk ki a mintát. Példának okáért, egy minta átlagát két dolog fogja befolyásolni: a sokaság átlaga (ha ez nagyobb, akkor várhatóan egy minta átlaga is nagyobb lesz) és az, hogy konkrétan melyik elemeket választottuk ki a sokaságból (adott sokasági átlag mellett is választhatunk  tökéletesen véletlen mintavétel mellett is!  pont kisebb, és pont nagyobb elemeket is). Mi értelemszeren csak az elsre vagyunk kíváncsiak, de sajnos a második hatása elvileg is kiküszöbölhetetlen. Bármilyen módszert is találunk ki arra, hogy a mintából hogyan következtessünk a sokaságra, teljesen biztos, hogy annak a végeredménye mintáról-mintára változni fog, azaz függeni fog attól, hogy konkrétan ,,hogyan nyúltunk bele a sokaságba, konkrétan milyen mintát vettünk. Ezt a jelenséget hívjuk mintavételi ingadozásnak. A szerencse épp az lesz, hogy ez a mintavételi ingadozás követni fog bizonyos (valószínségi) törvényszerségeket, így bár a fenti miatt elkerülhetetlenül hibázhatunk a következtetésnél, de annak természetérl fogunk tudni nyilatkozni. Amit nagyon fontos megérteni, hogy az elbb említett ,,hibázás alatt nem arra kell gondolni, hogy valamilyen értelemben rosszul vesszük a mintát. Ha egy 1000 fs sokaságból veszünk egy 30 fs mintát a sokasági átlag becslésére, akkor elfordulhat, mégpedig a legtökéletesebben véletlen mintavétel mellett is, hogy épp a 30 legkönnyebb embert választjuk ki a sokaságból. Természetesen, ha rosszul veszünk mintát (például akár tudattalan módon is, de a soványabb embereket szólítjuk meg a kérdívvel, hogy ne hozzuk zavarba a megkérdezetteket), akkor elképzelhet, hogy ennek megn a valószínsége, de akkor sem nulla ha tökéletesen véletlen a mintavétel. Csak épp  és itt jön a lényeg  extrém kicsi! Ha tényleg tökéletesen véletlen a mintavétel, azaz minden sokasági alanynak azonos esélye van a mintába kerülésre, akkor annak a valószínsége, hogy pont a 30 legsoványabbat választjuk ki épp \\(1/\\binom{30}{1000}\\approx 4\\cdot 10^{-56}\\)%. Így értend az, hogy a hiba valószínségszámítási úton, ,,sztochasztikusan limitálható: nem tudjuk kizárni, hogy ilyen  hatalmas méret  torzítás keletkezzen a mintából következtetés hatására de meg tudjuk mondani, hogy ennek mennyi a  szerencsére igen kicsi  valószínsége. Az ilyen okokból fakadó hibázást nevezzük mintavételi hibának. Nem csak olyan hiba van azonban, ami az  elkerülhetetlen  mintavételi ingadozásból adódik. Véthetünk hibát alullefedéssel és túllefedéssel (azaz a minta pontatlan körülírásával), véthetünk definíciós hibát a kérdéseknél, hibát az adatkódolás során, a végpont megválasztásánál stb. stb., de ami még fontosabb, hogy véthetünk hibát a minta kijelölésével (amennyiben a minta valójában nem reprezentatív a sokaságra nézve, lásd az elbbi példát a személyes megkérdezéses testtömeg-vizsgálatról), vagy épp megfigyeléses vizsgálat esetén a confounding-gal. Ezeket  tisztán statisztikai úton nem olyan könnyen kézben tartható  hibákat nevezzük egységesen nem-mintavételi hibáknak. 4.2 Becsléselmélet A becsléselmélet az induktív statisztika egyik f ága, feladata valamilyen sokasági jellemz értékének minta alapján történ megbecslése. A ,,becslés szó használata azért indokolt, mert az elbb kifejtettekbl világos, hogy mintavételi helyzetben csak valószínségi jelleg kijelentések tételére van mód. A sokasági jellemzt teljesen általánosan értjük (ha nem specifikáljuk közelebbrl, akkor általában \\(\\theta\\)-val jelöljük), bármilyen, a sokaság ismeretében számszeren meghatározható értéket jelenthet (például a sokaság átlagát, szórását, valamilyen tulajdonsággal rendelkez elemeinek az arányát stb.). Egy tipikus példa a sokaság átlagának/várható értékének becslése. Egy teljesen természetes gondolat, hogy ezt a jellemzt a minta átlagával igyekezzünk megbecsülni. Ez a naiv ,,tipp is mutatja már, hogy mit értünk precízen becslés alatt: egy olyan függvényt (neve becslfüggvényt vagy egyszeren becsl), melynek bemenetül a minta elemeit kell megadni, eredményként pedig kidobja a becslést az ismeretlen sokasági jellemzre. Egy \\(\\theta\\) sokasági jellemz becslfüggvénye tehát egy \\[ \\widehat{\\theta} = f\\left(x_1,x_2,\\ldots,x_n\\right) \\] függvény. (A becsült értéket a statisztikában általában is kalappal jelöljük.) Az elbbi naiv példánk azt jelenti, hogy ha a becsülni kívánt jellemz a sokasági várható érték (\\(\\theta=\\mu\\)), akkor reményeink szerint arra jó becsl lesz az \\[ f\\left(x_1,x_2,\\ldots,x_n\\right)=\\frac{\\sum_{i=1}^n x_i}{n}=\\overline{x} \\] függvény. Ahogy már korábban is megállapítottuk, ennek értéke két dologtól fog függeni: a \\(\\mu\\) értékétl (a valódi sokasági jellemztl), és attól, hogy konkrétan milyen mintát vettünk. Ez utóbbi hatás miatt természetesen a becslfüggvény eredménye minden egyes mintán más és más lesz, mintáról-mintára ingadozik. Visszatérve az egyszer példánkra az 1000 elem, véges sokaságból történ átlagbecslésre: kaphatjuk, mintavételtl függen, a legkönnyebb 30 ember átlagát is becslésként, és a legnehezebb 30 átlagát is. (És természetesen egy sor értéket a kett között.) De, amint már ott is megállapítottuk, ezen extrémumok valószínsége kisebb, a közbüls (és ilyen módon a valósághoz közelebb álló) értékeké pedig  szerencsére  nagyobb. Más szóval arra jutottunk, hogy a becslfüggvény értékeinek is van egy eloszlása: meg lehet adni, hogy adott tartományba es becslést mekkora valószínséggel adnak. Ezt nevezzük mintavételi eloszlásnak. Érdemes ezt egy szimulációval is megnézni! Vegyünk ugyanabból a sokaságból, melyet itt eloszlásával adtunk meg (\\(\\mathcal{N}\\left(30,70\\right)\\)), 10 darab 30 elem mintát, majd mindegyiknek számoljuk ki az átlagát: replicate(10, mean(rnorm(30, 70, 10))) ## [1] 71 72 69 67 72 68 71 67 67 71 Látszik, hogy  noha a sokaság állandó, és így a várható értéke is állandó, fixen 10  a minták átlaga, tehát a sokaság várható értékének mintából becsült értéke ingadozik. Elég sok ilyen szimulációt végezve, ez az ingadozás jól feltérképezhet (4.1. ábra). res &lt;- replicate(1e+05, mean(rnorm(30, 70, 10))) mean(res) ## [1] 70 hist(res, main = &quot;&quot;, ylab = &quot;&quot;, xlab = &quot;Mintaátlag&quot;) abline(v = 70, col = &quot;red&quot;, lwd = 2) Figure 4.1: A mintaátlag mintavételi eloszlásának meghatározása szimulációval, normális háttéreloszlás mellett. Ilyen módon további fontos kérdések is vizsgálhatóak, például megnézhetjük, hogy a becsült érték ingadozása hogyan függ a mintanagyságtól (4.2. ábra). res &lt;- replicate(1e+05, mean(rnorm(30, 70, 10))) plot(density(res), ylim = c(0, 0.7), main = &quot;&quot;, ylab = &quot;&quot;, xlab = &quot;Mintaátlag&quot;) res50 &lt;- replicate(1e+05, mean(rnorm(50, 70, 10))) lines(density(res50), col = &quot;blue&quot;) res300 &lt;- replicate(1e+05, mean(rnorm(300, 70, 10))) lines(density(res300), col = &quot;orange&quot;) abline(v = 70, col = &quot;red&quot;, lwd = 2) Figure 4.2: A mintavételi eloszlás függése a mintanagyságtól. Az ilyen vizsgálatok (szokták ezt Monte Carlo szimulációnak is nevezni) könnyen kivitelezhetek, és megfelel számítási kapacitás mellett bonyolult problémák kezelésére is alkalmas. Hátránya viszont, hogy nem kapunk analitikus eredményt (tehát a mintavételi eloszlást nem kapjuk meg matematikai képlettel felírt függvényként); ebben az egyszer példában ez sem jelent problémát, nemsokára vissza is fogunk rá térni. Felmerül a kérdés, hogy mit értünk precízen ,,jó becslfüggvény alatt. A gyakorlatban három tulajdonság különösen fontos: Elfogadjuk, hogy a becslfüggvény által szolgáltatott becslés mintáról-mintára ingadozik, de legalább az teljesüljön, hogy az ingadozás centrumában a valódi (sokasági) jellemz legyen, olyan értelemben, hogy átlagosan jó legyen a becsült érték. Precízen: egy becslfüggvényt torzítatlannak mondunk, ha a mintavételi eloszlásának a várható értéke a valódi (sokasági) jellemz. E tulajdonság neve: torzítatlanság. A fenti szimulációk azt sugallják, hogy az elbbi példában a mintaátlag torzítatlan becslje a sokasági várható értéknek (ezt persze még bizonyítani kellene). Ennek az ingadozásnak a mértéke lehetleg minél kisebb legyen, e tulajdonság neve: hatásosság. A hatásosságot a mintavételi eloszlás szórásával mérhetjük, egy becslfüggvényt hatásosnak mondunk, ha torzítatlan, és a torzítatlan becslk körében minimális szórású. A fenti szimulációk azt sugallják, hogy a mintanagyság növelésével egyre hatásosabbá válik a mintaátlag mint becslfüggvény. Azzal a kérdéssel, hogy hogyan lehet egy becslfüggvényt ,,kitalálni (tehát, ha megadnak egy paramétert, akkor mutatni egy rá vonatkozó, és persze lehetleg minél jobb statisztikai tulajdonságokkal bíró becslfüggvényt) nem foglalkozunk részletesebben, csak megemlítjük, hogy erre vonatkozóan jól bejáratott módszerek, ún. becslési elvek léteznek. (A legnevezetesebb közülük a maximum likelihood-elv, továbbá a plug-in becslés, a legkisebb négyzetek elve, a momentumok módszere és a Bayes-becslés.) Nézzünk minderre egy példát! Tekintsünk egy (eloszlásával adott) sokaságot, mely \\(X\\sim\\mathcal{N}\\left(\\mu,\\sigma_0^2\\right)\\) eloszlást követ. (Tehát tetszleges számú mintát vehetünk belle; minden egyes ilyen mintaelem egy ilyen eloszlásból származó, egymástól független szám lesz.) Azt állítjuk (és ezt hamarosan szabatosabban is be fogjuk bizonyítani), hogy ekkor a belle vett \\(n\\) elem minták átlaga, azaz a \\(\\mu\\) sokasági várható érték (mint sokasági jellemz) fenti becslfüggvénye \\(\\overline{x}\\sim\\mathcal{N}\\left(\\mu,\\sigma_0^2/n\\right)\\) eloszlást fog követni. (Tehát most feltételeztük, hogy azt a priori tudjuk, hogy normális eloszlású a sokaság, st, \\(\\sigma_0\\)-t is ismertnek vesszük, azaz csak a \\(\\mu\\) a kérdés.) Jegyezzük meg, hogy a sokasági jellemz, amit becsülni szeretnénk, itt a \\(\\mu\\) maga; az tehát nem követ semmilyen eloszlást, egy  konstans  szám! (Csak mi nem ismerjük.) A következkben ezt az állítást fogjuk matematikai úton, valószínségszámítási eszközökkel bebizonyítani, mégpedig a legegyszerbb esetre, a fent vázolt független és azonos eloszlású mintavételre. Legyen az \\(n\\) elem mintánk \\(X_1,X_2,\\ldots,X_n\\sim\\mathcal{N}\\left(\\mu,\\sigma_0^2\\right)\\) függetlenül (mivel a mintavétel azonos eloszlású is, így mindegyik ugyanolyan eloszlást követ, ezért volt azt elég egyszer leírni). Figyeljük meg, hogy itt nagy betket írtunk: ezek nem konkrét (realizálódott) értékek, hanem maguk is valószínségi változók. (Most ugyanis statisztikai analízisét adjuk a helyzetnek: úgy képzeljük, hogy még nem vettünk mintát, hanem épp ellenkezleg, azt vizsgáljuk, hogy ,,mi minden történhet amikor majd mintát veszünk.) Ezzel a becslfüggvényünk: \\[ \\overline{X}=\\frac{\\sum_{i=1}^n X_i}{n}. \\] Valószínségszámításból tudjuk, hogy 1. Normális eloszlású valószínségi változók összege normális (szépen megfogalmazva: a normális eloszláscsalád zárt a konvolúcióra). 2. A várható érték lineáris, így egy összeg várható értéke a várható értékek összege. 3. Ha ráadásul korrelálatlan (de csak ez esetben!), akkor a szórásnégyzetek  nem a szórások!  is összeadódnak. Ebbl a háromból már következik, hogy \\[ \\sum_{i=1}^n X_i\\sim\\mathcal{N}\\left(n\\mu,n\\sigma_0^2\\right). \\] Szintén valószínségszámításból tudjuk, hogy \\(\\mathbb{E}\\left(aX\\right)=a \\cdot \\mathbb{E}X\\) és \\(\\mathbb{D}^2\\left(aX\\right)=a^2 \\cdot \\mathbb{D}^2 X\\), ezekbl pedig már következik, hogy \\[ \\overline{X}=\\frac{\\sum_{i=1}^n X_i}{n} \\sim \\mathcal{N}\\left(\\mu,\\sigma_0^2/n\\right), \\] ahogy azt eredetileg állítottuk is. Ezzel igazoltuk, hogy ilyen körülmények mellett a mintaátlag torzítatlan becslje a sokasági átlagnak, st, kiszámoltuk a mintavételi szórását is. (Be lehetne látni kicsit komolyabb matematikai statisztikai eszközökkel, hogy ez ráadásul e körülmények között hatásos becsl is, tehát ennél kisebb mintavételi szórás el sem érhet a torzítatlan becslk körében.) Ez tehát azt jelenti, hogy a 2944.6 gramm nem csak a születési tömegek átlaga (ahogy azt az elbb mondtuk), hanem egyúttal a ,,vizsgálat beválogatási feltételeinek megfelel újszülöttek (fiktív, végtelen!) sokaságának várható értékének becslje is! Nem csak azt mondhatjuk, hogy 2944.6 gramm a mintaátlag (biztosan), hanem azt is, hogy ez a legjobb tippünk arra, hogy mennyi a sokaság várható értéke. Vegyük észre, hogy minket valójában ez utóbbi érdekel! Tehát bár a számérték itt pont ugyanaz lett (ez nincs mindig így!), az igazán érdekes eredmény az utóbbi megfogalmazás (hiszen minket nem konkrétan ez a 189 újszülött érdekel, hanem általában az ilyen újszülöttek jellemzinek viselkedése). Mind ez idáig azonban csak olyan becslfüggvényekrl beszéltünk, melyek egyetlen értéket, ,,a legjobb becslést adják vissza eredményként. Az ilyen becslést hívjuk pontbecslésnek. (Hiszen az eredménye egyetlen pont a számegyenesen.) Ez olyan szempontból azonban nem szerencsés, hogy az eredmény semmit nem mond az abban lév bizonytalanságról  noha, legalábbis becsülni, azt is tudnánk! Azt a becslési módszert, ami ezen túllép és explicite megjeleníti a becslésben lév bizonytalanságot is, intervallumbecslésnek nevezzük. Az intervallumbecslés központi eszköze az konfidenciaintervallum (CI): ez egy olyan intervallum, melyre igaz, hogy a hogy ha sokszor megismételnék a mintavételt, és mindegyik mintából megszerkesztenénk a CI-t, akkor ezen CI-k várhatóan adott, nagy hányada (például 95%-a) tartalmazná az igazi (sokasági) értéket. Ez esetben ezt az intervallumot 95% megbízhatóság melletti konfidenciaintervallumnak nevezzük. A 95%, mint paraméter neve megbízhatósági szint, általában \\(1-\\alpha\\)-nak nevezzük (tehát \\(\\alpha=0,\\!05\\) mellett beszélünk 95%-os megbízhatóságról). Els ránézésre kicsit furcsa lehet ez a jelölés, de majd a hipotézisvizsgálatnál is látni fogjuk, hogy \\(\\alpha\\)-val valamilyen hibázás jelleg mennyiséget szeretnénk jelölni, nem jóságot. Az induktív statisztikában tehát elfogadjuk (kénytelenek vagyunk elfogadni), hogy a becslésünk eredménye mintáról mintára változik, és így nem tudhatjuk biztosan, hogy adott mintából számolt becslés hogyan viszonyul a valódi (sokasági) értékhez  a konfidenciaintervallum azonban épp azt próbálja megragadni, hogy  adott minta alapján!  mire tippelhetünk, ,,vélheten hol lehet a valódi sokasági érték (adott, nagy megbízhatósággal). Ez természetesen már nem egyetlen szám, hanem egy tól-ig intervallum lesz a jellemzre vonatkozóan. Hogy mit jelent a ,,vélheten és a ,,megbízhatóság, az pontosításra szorul, erre tárgyalásunk legvégén fogunk visszatérni. Adott megbízhatósági szint mellett minél szkebb a CI, annál kisebb a bizonytalanság a becslésünkben. Természetesen adott becslés mellett a CI szélességét a megbízhatósági szint fogja meghatározni: kis megbízhatóság mellett szk intervallumot is mondhatunk, de ha nagy megbízhatóságra van szükségünk, akkor csak széles limiteket tudunk szabni. Itt tehát kompromisszumot kell kötnünk: az se jó, ha nagy biztonsággal tudjuk, hogy nem igazán tudjuk, hogy hol van az igazi érték, és az se, ha nagyon kis biztonsággal tudjuk, hogy igen pontosan hol van A 95% egy tipikus, gyakorlatban igen sokszor használt kompromisszum ez ügyben. Nézzünk erre is egy számszer példát! Folytatva elz példánkat, tudjuk, hogy \\(\\overline{X} \\sim \\mathcal{N}\\left(\\mu,\\sigma_0^2/n\\right)\\). Ebbl következik, hogy \\[ \\frac{\\overline{X}-\\mu}{\\sigma_0/\\sqrt{n}}\\sim\\mathcal{N}\\left(0,1\\right), \\] azaz \\[ \\mathbb{P}\\left(-z&lt;\\frac{\\overline{X}-\\mu}{\\sigma_0/\\sqrt{n}}&lt;z\\right)=\\Phi\\left(z\\right)-\\Phi\\left(-z\\right)=\\Phi\\left(z\\right)-\\left[1-\\Phi\\left(z\\right)\\right]=2\\Phi\\left(z\\right)-1. \\] Ha ezt a valószínséget \\(\\left(1-\\alpha\\right)\\)-nak választjuk (a megbízhatósági szint fenti értelme miatt), akkor kapjuk, hogy \\(\\Phi\\left(z\\right)=1-\\frac{\\alpha}{2}\\) azaz \\(z=\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\). Erre a mennyiségre bevezetve a \\(z_{1-\\frac{\\alpha}{2}}\\) jelölést, rögtön látható, hogy a \\(\\left[\\mu-z_{1-\\frac{\\alpha}{2}}\\frac{\\sigma_0}{\\sqrt{n}},\\mu+z_{1-\\frac{\\alpha}{2}}\\frac{\\sigma_0}{\\sqrt{n}}\\right]\\) tartományba \\(1-\\alpha\\) valószínséggel esik \\(\\overline{X}\\). Ezt nevezhetnénk ,,deduktív statisztikának, hiszen itt a sokaságot tekintettük ismertnek, és ez alapján következtettünk a minta viselkedésére. Átrendezve ,,kapjuk a minket érdekl az induktív statisztikát: \\[ \\mathbb{P}\\left(-z_{1-\\frac{\\alpha}{2}}&lt;\\frac{\\overline{X}-\\mu}{\\sigma_0/\\sqrt{n}}&lt;z_{1-\\frac{\\alpha}{2}}\\right)=1-\\alpha \\Rightarrow \\mathbb{P}\\left(\\overline{X}-z_{1-\\frac{\\alpha}{2}}\\frac{\\sigma_0}{\\sqrt{n}}&lt;\\mu&lt;\\overline{X}+z_{1-\\frac{\\alpha}{2}}\\frac{\\sigma_0}{\\sqrt{n}}\\right)=1-\\alpha. \\] Ekkor a konfidenciaintervallum immár egy konkrét mintára a fenti alapján: \\[ \\left[\\overline{x}-z_{1-\\frac{\\alpha}{2}}\\frac{\\sigma_0}{\\sqrt{n}},\\overline{x}+z_{1-\\frac{\\alpha}{2}}\\frac{\\sigma_0}{\\sqrt{n}}\\right]. \\] Tipikusan \\(\\alpha=0,\\!05\\), amint mondtuk, ekkor \\(1-\\alpha=95\\)%-os konfidenciaintervallumról beszélünk. Nagyon fontos megfigyelni, hogy csak mintavétel eltt vannak valószínségi változók (,,nagy betk), utána már nem (,,kis betk)  ezért használtuk a megbízhatóság szót a valószínség helyett. Mintavétel után ugyanis már nem tehetünk olyan kijelentést, hogy a megkonstruált CI 95%-os ,,valószínséggel tartalmazza a valódi, sokasági paramétert, hiszen ha már egy realizálódott minta van a kezünkben, akkor elvileg akárhol lehet a valódi érték, errl semmi közelebbit nem tudunk mondani. Valószínséget csak a (szükségképp képzeletbeli) ,,ismételt mintavételi értelemben tudunk behozni a feladatba, ezért használjuk megkülönböztetésül a megbízhatóság szót. Így kell érteni, hogy a konfidenciaintervallum jellemzi, hogy ,,hol lehet a valódi (sokasági) paraméter. A születési tömegek 95%-os konfidenciaintervalluma [2840,03049,2] gramm. (Megjegyezzük, hogy ez a fentitl kissé eltér módszerrel készült, ami tekintettel van arra is, hogy itt most  szemben a fenti példával  nem ismerjük a priori a sokaság szórását.) Ez azt jelenti, hogy a legjobb tippünk a születési tömeg sokasági várható értékére a 2944.6 gramm, de azt is tudjuk ezen felül mondani, hogy bár ez csak bizonytalan tipp (hiszen a becsült érték mintáról-mintára ingadozik), de 95%-os megbízhatósággal azért kijelenthet, hogy nem kisebb a keresett, ismeretlen sokasági várható érték mint 2840,0 gramm és nem nagyobb mint 3049,2 gramm. (Amit úgy értünk, hogy azt becsüljük, hogy ha a sokaságból 100 mintát vennénk, és mindegyikbl ugyanígy megkonstruálnánk a konfidenciaintervallumokat, akkor várhatóan 95 esetben tartalmazná a CI a valódi, sokasági értéket.) Érdemes megfigyelni, hogy a konfidenciaintervallum két végpontja szimmetrikus a pontbecslésre; ez a várható érték becslésére jellemz, de más paramétereknél nem feltétlenül van így. Itt is hasznos mindezeket egy szimulációval szemléltetni (4.3. ábra). SimData &lt;- data.frame(idx = 1:100, CI = t(replicate(100, TeachingDemos::z.test(rnorm(30, 70, 10), stdev = 10)$conf.int))) Hmisc::Dotplot(idx ~ Hmisc::Cbind(NA, CI.1, CI.2), data = SimData, abline = list(v = 70, col = &quot;red&quot;, lwd = 2), ylab = &quot;&quot;) Figure 4.3: Konfidenciaintervallumok szemléltetése szimulációval. 4.3 Hipotézisvizsgálat Az induktív statisztika másik nagy ága a hipotézisvizsgálat. A hipotézisvizsgálat nagyon sok szempontból a becsléselmélet, ezen belül is az intervallumbecslés elméletének ikertestvére (ami ekvivalens, csak átfogalmazottan felírt egyenletekre vezet), mégis, saját szóhasználata, fogalomköre, és hatalmas gyakorlati jelentsége indokolja, hogy külön tárgyaljuk. Amíg a becsléselmélettl azt vártuk, hogy nyilatkozzon egy számunkra ismeretlen jellemzrl, addig a hipotézisvizsgálat esetében van elzetes elképzelésünk a jellemz értékérl (például, hogy egy adott számmal egyenl)  csak épp nem tudjuk, hogy ez igaz-e. Ha az elzetes feltevésünk mintára vonatkozna, akkor nem is volna semmi probléma: kiszámítjuk a jellemzt a mintából, és megnézzük, hogy teljesült-e a feltevésünk. Mivel azonban a feltevés a sokaságra vonatkozik, így megint csak visszatérünk oda, hogy errl biztos döntést hozni lehetetlen minta alapján  de valószínségit lehet. Nem tudjuk megmondani, hogy a sokaság átlagos testtömege 70 kg-e, ha a mintabeli átlag 65 kg de meg fogjuk tudni mondani (egyéb mintaadatok felhasználásával), hogy mennyire hihet, hogy 70 kg a sokasági átlag. Erre szolgál a hipotézisvizsgálat. Már most fontos megjegyezni, hog a hipotézisvizsgálat logikája bizonyos szempontból fordított: az elbbi kérdés ellentétére keresi a választ, arra, hogy ha 70 kg lenne a sokasági átlag, akkor mennyire lenne valószín, hogy ettl olyannyira eltér eredményt kapunk, mint a 65 (vagy annál is kisebb). Ha nagyon, akkor azt mondjuk, hogy ,,minden bizonnyal nem 70 kg volt az átlag. A problémát nyilván az adja, hogy  maradva a fenti példánál  nem tudhatjuk, hogy mi okozta ezt az 5 kg különbséget. Valójában tényleg 70 kg a sokaság átlaga, csak a mintavételi ingadozás játéka miatt pont olyan mintát fogtunk ki, amiben picit kisebb volt az átlag, vagy ez az 5 kg különbség olyan nagy, ami túlmutat a mintavételi ingadozáson, és azt kell feltételeznünk, hogy a hátterében sokasági hatás (is) van (tehát, hogy a sokasági átlag kisebb mint 70 kg)? Amint a fentiekbl is kiderült, a hipotézisvizsgálat mindig a sokaságra megfogalmazott állításból indul ki. Valójában nem is egy, hanem rögtön két állítást használ a hipotézisvizsgálat; nevük nullhipotézis (\\(H_0\\)) és ellenhipotézis (\\(H_1\\)) melyek jellemzen egymás komplementerei. (Azaz egymást kizárják, de a kettbl valamelyik biztosan fennáll.) A fenti példát így írhatnánk: \\[\\begin{align*} H_0&amp;: \\mu = \\mu_0\\\\ H_1&amp;: \\mu \\neq \\mu_0\\\\ \\end{align*}\\] úgy, hogy \\(\\mu_0\\)=70 kg. Amit fontos észben tartani, hogy hipotézisvizsgálatnál az ers döntés mindig az elutasítás tud lenni, ezért a legtöbb próba úgy van megszerkesztve, hogy a szakmailag ,,izgalmas állítás, a tudományos nóvum (hatásos a gyógyszer, van eltérés a laboreredményben stb.) az ellenhipotézisbe kerüljön. Pontosan emiatt az elutasítás esetén nagyon gyakran  szinonimaként  azt mondjuk, hogy a ,,próba szignifikáns. A hipotézisvizsgálat központi eszköze a próbafüggvény (vagy más szóval tesztstatisztika). Az egész eszközt együtt tesztnek vagy próbának nevezzük. A próbafüggvény a mintaelemek függvénye, ilyen módon a próbafüggvénynek is eloszlása lesz. És itt jön a kulcs: a próbafüggvényt úgy választjuk meg, hogy \\(H_0\\) fennállása esetén valamilyen pontosan ismert eloszlást kövessen; ezt szokás nulleloszlásnak is nevezni. Természetesen a próbafüggvény konkrét értéke függeni fog a mintaelemektl, de az eloszlása nem függhet ettl (sem más, ismeretlen paramétertl, ha volna ilyen). Hogy megértsük, hogy ez miért lesz alkalmas a hipotézispárról történ (valószínségi) döntéshozatalra, nézzünk egy konkrét példát. Folytatva az elz példát, tegyük fel, hogy sokaságunk eloszlása normális, ismert szórással. Amint már megbeszéltük, ekkor \\(\\overline{X}= \\sim \\mathcal{N}\\left(\\mu,\\sigma_0^2/n\\right)\\). Ez tehát a mintaelemek függvénye, és elvileg próbafüggvénynek is nevezhet, mert ha érvényesítjük rajta \\(H_0\\)-t (azaz \\(H_0\\)-t igaznak fogadjuk el), akkor azt kapjuk, hogy \\(\\overline{X}= \\sim \\mathcal{N}\\left(\\mu_0,\\sigma_0^2/n\\right)\\), ami valóban már nem függ ismeretlen paramétertl. Ezzel, és a technikailag szintén megfelel \\(\\overline{X}-\\mu_0\\sim \\mathcal{N}\\left(0,\\sigma_0^2/n\\right)\\)-nel is az a gyakorlati baj azonban, hogy nagyon nehézkes lenne a használatuk, hiszen bár a nulleloszlás ismert, de minden \\(\\mu_0\\)-ra, \\(\\sigma_0\\)-ra és \\(n\\)-re más és más  azaz ezektl függen minden egyes hipotézisvizsgálathoz el kéne keresni az adott eloszlást. A \\(\\overline{X}-\\mu_0\\) azonban már mutatja az utat: próbálkozzunk a \\(\\frac{\\overline{X}-\\mu_0}{\\sigma/\\sqrt{n}}\\) próbafüggvénnyel (jele általában \\(Z\\))! Ez már minden szempontból tökéletes lesz, hiszen nulleloszlása \\(\\mathcal{N}\\left(0,1\\right)\\), azaz minden paramétertl függetlenül ugyanaz; egyetlen eloszlással elvégezhet az összes ilyen típusú hipotézisvizsgálat e körülmények között. Foglaljuk össze hol tartunk! Konstruáltunk egy olyan függvényét a mintaelemeknek, melynek ismerjük az eloszlását ha fennáll a nullhipotézis. Ki tudjuk azt is számolni, hogy mennyi ennek a próbafüggvénynek az értéke a konkrét (realizálódott) mintánkból; ezt szokás empirikus értéknek (\\(z_{\\mathrm{emp}}\\)) is nevezni. Innentl úgy okoskodhatunk: biztos döntést lehetetlen hozni (ez az elbbi példán nagyon jól látszik: a \\(\\mathcal{N}\\left(0,1\\right)\\) nulleloszlás tartója az egész számegyenes, tehát még ha fenn is áll a nullhipotézis, elvileg akármilyen szám realizálódhat belle, az elvileg bármilyen szám lehet a mintából kiszámított próbafüggvény értéke, azaz \\(z_{\\mathrm{emp}}\\)), de mégis, mennyire hihet, hogy a szaggatott vonallal jelölt érték a folytonosan behúzott eloszlásból realizálódott a következ esetekben (4.4. ábra). Figure 4.4: A hipotézisvizsgálat alapgondolatának szemléltetése. Érezhet, hogy bár elvileg mindkett elfordulhat, de a bal oldalit hajlamosak vagyunk elhinni, a jobb oldalinál viszont épp ellenkezleg, , hogy azt gondoljuk, hogy az empirikus érték valójában más eloszlásból realizálódott. Noha elvileg a bal oldali is jöhet más eloszlásból, és a jobb oldali is ebbl  ezért a bizonytalan megfogalmazások, mutatva, hogy ezek csak valószínségi állítások. Precízebben megfogalmazva: az kicsi valószínség esemény (\\(\\mathcal{N}\\left(0,1\\right)\\) eloszlás esetén), hogy \\(\\pm 3\\)-on kívül számot kapjunk. Ha mégis ilyen érték jön ki, akkor joggal kérdjelezzük meg, hogy a próbafüggvény ilyen eloszlást követett  márpedig, ha fennáll a nullhipotézis, akkor ilyen eloszlást kellett követnie, így más szóval mi most arra következtettünk, hogy nem áll fenn a nullhipotézis! Ez persze bizonytalan döntés, és itt jól látszik ennek az oka: nagyon is kijöhet \\(\\pm 3\\)-on kívül szám még akkor is, ha fennáll a nullhipotézis, st, ennek a valószínsége akár számszeren is meghatározható (\\(\\Phi\\left(-3\\right)+\\left[1-\\Phi\\left(3\\right)\\right]\\) ami kb. 0,27%). Ha a \\(\\pm 3\\)-on kívüli tartományra mondjuk az, hogy ide es empirikus tesztstatisztika esetén ,,már nem hisszük el, hogy fennállt a nullhipotézis, akkor pontosan 0,27% valószínséggel fogunk hibás döntést hozni: ekkora a valószínsége ugyanis, hogy fennálló \\(H_0\\) esetén is ilyen extrém tesztstatisztika jöjjön ki. Ha ez számunkra túl nagy, akkor megtehetjük, hogy mondjuk csak a \\(\\pm 4\\)-en kívüli értékeket tekintjük ,,gyanúsnak  csakhogy ekkor a valódi különbségek felderítését is megnehezítjük. Az tehát egy kompromisszum eredménye, hogy ,,hol húzzuk meg a határt. A gyakorlatban ezt úgy hajtjuk végre, hogy az eloszlás legextrémebb, tehát a nullhipotézis fennállása esetén várt értéktl legtávolabb es részein (a mostani példánkban: mindkét szélén szimmetrikusan) kijelölünk egy olyan tartományt, melynek egy adott, kicsi érték (jele \\(\\alpha\\)) a valószínsége. Más szóval azt mondjuk, hogy ebbe az intervallumba elvileg ugyan eshet egy realizálódott érték akkor is, ha a nulleloszlás fennáll, de ennek olyan kicsi a valószínsége, hogy ezt már nem tartjuk hihetnek (hivatkozva arra, hogy ez a tartomány fekszik a legtávolabb nullhipotézis fennállása esetén várt értéktl). Tökéletesen látszik azonban, hogy csak bizonytalan döntést tudunk hozni: ez a kijelentésünk automatikusan az esetleges hibázás elfogadását jelenti  nagyon is tudjuk, hogy ebbe a tartományba eshet a realizálódott érték a nulleloszlás fennállása esetén is, mi mégis azt mondjuk, hogy ekkor már nem hisszük el a nullhipotézist. Mivel a normális eloszlás tartója az egész számegyenes, így egyértelm, hogy ennél jobbat nem tudunk tenni, valahol korlátot kell húznunk. Ilyen módon kijelöltük, hogy milyen empirikus tesztstatisztika-értékek esetén fogadjuk el a nullhipotézist (elfogadási tartomány), és milyenek esetén nem (elutasítási (vagy kritikus) tartomány). Látható, hogy a tartományok helyét az \\(\\alpha\\) valószínség szabja meg, ennek a valószínségnek a neve: szignifikanciaszint. Ebben a feladatban a túl magas és a túl alacsony tesztstatisztika érték is ugyanúgy az elvetés irányába mutat, így az elfogadási tartományt valóban a nullára szimmetrikusan jelöljük ki. Ha például azt mondjuk, hogy a szignifikanciaszint 5%, azaz a legextrémebb 5%-nyi területen utasítsunk el, akkor azt úgy tehetjük meg, hogy a nulleloszlás alsó és a fels szélén is 2,5-2,5%-nyi valószínséget vágunk le. Ezeket a ,,szétvágási pontokat, melyek az elutasítási és az elfogadási tartományokat határolják, kritikus értékeknek szokás nevezni. Mivel a nulleloszlás ismert, így ezek könnyen számszersíthetek is mint a 0,025-ös és a 0,975-ös kvantilisei az eloszlásnak; például \\(\\alpha=5\\)%-ra a két kritikus érték a \\(c_a=-1,\\!96\\) alsó kritikus érték és a \\(c_f=+1,\\!96\\) fels kritikus érték. Mindezeket összefoglalóan szemlélteti a 4.5. ábra, \\(\\alpha=5\\) és \\(\\alpha=1\\)%-os szignifikanciaszintekre. Figure 4.5: A hipotézisvizsgálat döntésének szemléltetése két szignifikanciaszint mellett. Amint arra már utaltunk is, \\(\\alpha\\) beállításával a hipotézisvizsgálatban elkövethet kétféle hiba között egyensúlyozunk. Az egyik tévedési lehetség, hogy fennáll a nullhipotézis, mi mégis elvetünk (ennek neve elsfajú hiba; a valószínsége felett nagyon is ers kontrollunk van, hiszen az épp \\(\\alpha\\)); a másik hibázási lehetség, hogy elvethetnénk a nullhipotézis, mi mégis elfogadunk (ennek neve másodfajú hiba, a valószínségét \\(\\beta\\)-val szokás jelölni; \\(\\beta\\) értékét nem tudjuk jól kézben tartani, hiszen attól is függ, hogy konkrétan milyen ellenhipotézis áll fenn, amit általában mi sem tudhatunk). Ha \\(\\alpha\\)-t növeljük (,,beljebb húzzuk a kritikus értékeket, növeljük az elutasítási, csökkentjük az elfogadási tartomány méretét), akkor megemeljük a téves elutasítás, és lecsökkentjük a téves elfogadás valószínségét, ha \\(\\alpha\\)-t csökkentjük (,,kijjebb toljuk a kritikus értékeket, növeljük az elfogadási, csökkentjük az elutasítási tartomány méretét), akkor megemeljük a téves elfogadás, és lecsökkentjük a téves elutasítás valószínségét. Az \\(\\alpha=5\\)% egy tipikus kompromisszum a kétféle hibázás között. Kiegészítésként megjegyezzük, hogy \\(\\left(1-\\beta\\right)\\)-t a próba erejének szokás nevezni (hiszen azt mutatja meg, hogy ha a valóságban nem áll fenn a nullhipotézis, akkor azt mekkora valószínséggel fogjuk detektálni). A fentiekbl is érezhet, hogy egy próba eredményének olyan formában történ megadása, hogy ,,5%-on szignifikáns nem a legszerencsésebb, hiszen rögtön adódik a kérdés: vajon 1%-on is szignifikáns lett volna? És 0,1%-on? Nem mindegy, hiszen egy olyan eredmény, mely 5%-on szignifikáns, de 4%-on nem, sokkal nagyobb bizonytalanságú, mint egy olyan, ami 0,1%-on is szignifikáns. Megoldás lehetne a tesztstatisztika konkrét értékének megadása, ez azonban gyakorlati szempontból nehézkes, hiszen így minden esetben meg kéne nézni, hogy mi a nulleloszlás (hiszen a tesztstatisztika empirikus értékét muszáj ahhoz viszonyítani). Éppen ezért a mai gyakorlatban inkább azt adják meg, hogy melyik lenne az a szignifikanciaszint, ami mellett a tesztstatisztika empirikus értéke épp az elutasítás és az elfogadás határa kerülne. Ennek neve: \\(p\\)-érték (vagy empirikus szignifikanciaszint). Például, gondoljuk azt, hogy próbánk 5%-on elutasít. Ekkor elkezdjük az \\(\\alpha\\)-t csökkenteni (ezzel kijjebb húzzuk a kritikus értékeket, bvítjük az elfogadási, szkítjük az elutasítási tartomány). Elérjük a 4%-ot, az empirikus tesztstatisztikánk még mindig az elutasítási tartományban van, tovább csökkentjük az \\(\\alpha\\)-t, és így tovább míg nem egyszer csak azt vesszük észre, hogy mondjuk 2,31%-on még elutasít a teszt, de 2,29%-on már nem. Ekkor azt mondjuk, hogy a teszt \\(p\\)-értéke 2,3%. A \\(p\\)-érték tehát nem más, mint a szignifikanciaszint akkor, ha a megfelel (alsó vagy fels) kritikus értéket a tesztstatisztika empirikus értékének helyére helyezzük át. (A másikat pedig, értelemszeren, az ellentétére, hiszen a kritikus értékek ebben ez esetben  ahogy már megbeszéltük  szimmetrikusak.) Ebbl az is következik, hogy a \\(p\\)-érték számszeren a nulleloszlás integrálja az empirikus tesztstatisztikától extrémebb irányba (illetve ennek kétszerese), ugyanúgy, ahogy az \\(\\alpha\\) is  definíció szerint  a nulleloszlás integrálja a kritikus értékektl extrémebb irányokba (és itt, ahogy megbeszéltük, a kritikus érték szerepét az empirikus tesztstatisztika játssza). Ennek meghatározása tehát manapság már számítástechnikai szempontból is problémamentes. Világos, hogy \\(p\\)-érték az elvetésben való bizonyosságunkat fejezi ki. Ez az eredményközlés azért rendkívül praktikus, mert  szemben az elzekkel  az olvasó ,,elvégezheti magának a hipotézisvizsgálatot, és bármilyen szignifikanciaszinten döntést hozhat. A \\(p\\)-értéknél magasabb szignifikanciaszinteken elutasítás lesz a döntés (ekkor bvebb az elutasítási tartomány, bele fog esni az empirikus tesztstatisztika), a \\(p\\)-értéknél alacsonyabb szinteken pedig elfogadás (az elutasítási tartomány szkebb, az empirikus tesztstatisztika az elfogadási tartományba fog esni). Végezetül egy fontos gyakorlati kérdésre hívjuk fel a figyelmet. Amint már megbeszéltük, az \\(\\alpha\\) azt mutatja meg, hogy egy adott próba mekkora valószínséggel ad téves jelzést. (Emlékezzünk rá, hogy általában mi az elutasítást keressük!) Igen ám, de ha mi két próbát végzünk egymástól függetlenül úgy, hogy akkor is találatot deklarálunk, ha legalább az egyik teszt szignifikáns lett, akkor valójában már nem \\(\\alpha\\) valószínséggel kapunk jelzést akkor is, ha nincs hatás (egyik esetben sem), hanem \\(1-\\left(1-\\alpha\\right)^2\\) valószínséggel! (Hiszen a hibás jelzés annak a komplementere, hogy mindkét teszt jó döntés ad, mivel pedig függetlenek, ezek valószínsége összeszorzódik.) Ez pedig nagyon nem mindegy, a tipikus \\(\\alpha=5\\)%-ra ez a valószínség már 9,75%! Tehát valójában majdnem a nominális szignifikanciaszint kétszerese lesz annak a valószínsége, hogy kapunk elutasítást  miközben a valóságban nincs is hatás egyik esetben sem! Ezt a jelenséget szokás \\(\\alpha\\)-inflációnak nevezni. (A kétféle \\(\\alpha\\)-t pedig néha megkülönböztetésül comparisonwise (\\(\\alpha_C\\)) \\(\\alpha\\)-nak illetve familywise (\\(\\alpha_F\\)) \\(\\alpha\\)-nak nevezik. Az elbbi annak a valószínsége, hogy egy teszt hibás jelzést ad (ez az eddig tárgyalt \\(\\alpha\\)), az utóbbi annak a valószínsége, hogy tesztek egy családjából legalább egy lesz, ami hibás jelzést ad.) Az összefüggés a kett között tehát: \\[ \\alpha_F = 1-\\left(1-\\alpha_C\\right)^k, \\] ahol \\(k\\) az elvégzett próbák száma. Azt a helyzetet, amikor egymással párhuzamosan több, egymástól független hipotézisvizsgálatot futtatunk (és vagylagosan keresünk szignifikáns eredményt), többszörös összehasonlítások helyzetének szokás nevezni. A dolog azt sugallja számunkra, hogy ha sok tesztet végzünk párhuzamosan, akkor valamit tenni kell az ellen, hogy ne találjuk túl könnyen fals elutasításokat. A legegyszerbb megoldás, ha a tesztenkénti (comparisonwise) szignifikanciaszintet lecsökkentjük. Például, az ún. Bonferroni-egyenltlenség szerint \\(1-\\left(1-\\alpha\\right)^k\\leq \\alpha\\cdot k\\), ezért durva becsléssel úgy korrigálhatjuk a szignifikanciaszintet, hogy elosztjuk a célszintet az elvégzett hipotézisvizsgálatok számával. Ez garantálja, hogy a \\(k\\) teszt elvégzését együttesen tekintve sem lehet a kitzött szignifikanciaszint feletti az elsfajú hibák aránya. A módszer hátránya, hogy túl drasztikus: annyira megnehezíti a nullhipotézis elvetését, hogy a valós különbségek is ,,el fognak veszni. Vannak módszerek, melyek ezt enyhítik (pl. HolmBonferroni-korrekció), illetve melyek teljesen más elven próbálják elérni az \\(\\alpha\\)-infláció enyhítését (pl. FDR). Ennek a kérdéskörnek például a microarray adatok kiértékelése kapcsán (ahol elképeszt mennyiség tesztet kell függetlenül végezni) nagyon megntt a jelentsége; ettl eltekintve azonban az orvosok általában nem viszik túlzásba a védekezést ez ellen Itt hívjuk fel a figyelmet az ún. szignifikanciavadászat jelenségére. Ez lényegében nem más, mint a többszörös összehasonlítások helyzetének rosszindulatú kiaknázása inkorrekt következtetésre. A szignifikanciavadászat jelenségét inkább egy példával illusztráljuk: tegyük fel, hogy bizonyítani akarjuk, hogy a hétfn és kedden született emberek laboreredményei között szignifikáns eltérés van. Bár ez ránézésre látható módon abszurdum, a fentiek kihasználásával tulajdonképpen nem is nehéz bizonyítani: manapság már a rutinszeren vizsgált laborparaméterek száma is eléri a 20-30-at, így nincs más dolgunk, mint mindegyiket összehasonlítani! Természetesen valós különbség sehol nem lesz, de mivel 5% valószínséggel mindegyik adhat téves jelzést, így 30 között már az lenne a meglep, ha nem kapnánk egyetlen elutasítást sem. Ha a vizsgálatot  korrekt módon  úgy publikáljuk le, hogy összehasonlítottunk 30 laborváltozót 5%-on, és közülük 1 esetben, az XYZ-nél szignifikáns különbséget találtunk, akkor mindenki rögtön tudni fogja, hogy mi történt (azaz, hogy nem jelenthetjük ki, hogy találtunk bármit is). Igen ám, de ha inkorrekt módon játszunk, akkor azt tesszük, hogy a cikket úgy írjuk meg, hogy mi elre tudtuk, hogy XYZ-ben lesz különbség (mert van egy ragyogó kórélettani modellünk, mely az XYZ termelését a születés napjával hozza összefüggésbe), és ezért célirányosan XYZ-t leteszteltük, és lám: valóban szignifikáns különbséget is kaptunk! Ezzel szemben nehéz védekezni, hiszen magából az eredményközlésbl nem lehet rájönni, hogy mi történt (de természetesen a vizsgálat reprodukciója azonnal lebuktatja a csalást). Zárásként részletesebb indoklás nélkül felhívjuk három összefüggésre a figyelmet. Nagyon fontos gyakorlati probléma, hogy adott feladat vizsgálatára konkrétan melyik próbát használjuk. Ez közel sem triviális kérdéskör, ugyanis a feladat önmagában még nem determinálja a próbát: sok feladat van, amire akár tucatnyi különböz próba is elérhet; ezek tipikusan az elfeltevéseikben különböznek. (Azaz, hogy milyen megkötésekkel élnek a sokaságra vonatkozóan.) Ennek kapcsán arra hívjuk fel a figyelmet, hogy egyrészt ha egy próba elfeltevései nem teljesülnek, de mi mégis alkalmazzuk, akkor nem garantált, hogy valid végeredményt kapunk, másrészt viszont a több elfeltevésre épít próbáknak általában kisebb az erejük. A tanulság, hogy mindig annyi elfeltevésre épít próbát használjunk, amennyit tudunk, se többet se kevesebbet: amely elfeltevésekrl tudjuk, hogy teljesülnek (a priori!) azokat építsük be a próbaválasztásba de többet ne. Rögtön itt érdemes megjegyezni, hogy  bár egyes statisztikai programcsomagok notóriusan az ellenkezjét sugallják  elvileg nem illik az alapján dönteni, hogy milyen próbát használunk, hogy az elfeltevéseit mintán leellenrizzük. Ezért hangsúlyoztuk az elbbi pontban, hogy a feltevésekrl kell döntenünk (korábbi eredmény, másik mintán végzett teszt stb. alapján). Végül felhívjuk a figyelmet, hogy egy próba erejét önmagában növeli a nagyobb mintanagyság. Pontosan ezért a klasszikus mondás szerint: ,,kis hatás kimutatásához nagy minta kell, nagy hatáshoz elég a kisebb minta is!. Mutatunk egy példát a hipotézisvizsgálat alkalmazására is: vizsgáljuk meg azt a kérdést, hogy a dohányzó anyák újszülötteinek születési tömege eltér-e a nemdohányzó anyák újszülötteitl! Az els kérdés, hogy mit értünk az alatt, hogy ,,eltér. Ezt többféleképp is lehetne operacionalizálni, most maradjunk annál a  kézenfekv, és klinikailag is releváns  megközelítésnél, hogy a várható születési tömegük kisebb-e. (Tehát a kérdést a várható értékek egyezésére hegyezzük ki, nem az érdekel minket, hogy például a szórása a születési tömegeknek eltér-e a két csoportban.) Az adatbázisban 115 nemdohányzó és 74 dohányzó anyától származó újszülött van. Gyorsan kiszámolhatjuk, hogy az elbbi csoportban az újszülöttek átlagos születési tömege 3055,7 gramm, míg az utóbbiban 2771,9 gramm. Mondhatjuk akkor, hogy a dohányzó anyák újszülöttjei kisebb tömegek? Természetesen nem! Ez ugyanis csak annyit mondott, hogy a mintában kisebb a tömegük, de minket természetesen nem a konkrét minta érdekel, hanem a sokaság! Kijelenthetjük ez alapján, hogy a sokaságban is kisebb a dohányzó anyák újszülöttjeinek a várható születési tömege? Nem, a helyzet nem ilyen egyszer: elképzelhet, hogy mindkét csoportnak ugyanannyi (a sokaságban!) a várható születési tömege, csak épp pont olyan mintát vettünk, amiben a dohányzó anyáknál ez kisebb. (Ez természetesen tökéletes mintavétel esetén is elfordulhat  mintavételi ingadozás, ugyebár!) St, akár az is lehet, hogy épp a dohányzó anyák újszülöttei nagyobb születési súlyúak várhatóan, csak a mintavétel ördöge az  csoportjukból pont kicsi, a nemdohányzó csoportból meg nagyobb újszülötteket dobott ki. A kérdésrl tehát biztosat nem lehet mondani  de statisztikai próbával valószínségi kijelentést tehetünk. Elsként döntenünk kell arról, hogy milyen próbát alkalmazzunk. Ennek a részletei számunkra most nem fontosak, a lényeg csak a végeredmény: a körülmények (két független csoport, aránylag nagy mintanagyság mindkét csoportban, a priori nem ismert sokasági szórás) a választásunk az ún. Welch-próbára esik. Ennek nullhipotézise, hogy a két csoport várható értéke között nincs különbség, ellenhipotézise, hogy van, a két várható érték nem egyezik. Végezzük el a próbát: t.test(bwt ~ smoke, data = birthwt) ## ## Welch Two Sample t-test ## ## data: bwt by smoke ## t = 3, df = 170, p-value = 0.007 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 79 489 ## sample estimates: ## mean in group 0 mean in group 1 ## 3056 2772 A \\(p\\)-érték: \\(p=0,\\!007\\), ez minden szokásos szignifikanciaszintnél kisebb (még az 1%-ot sem éri el), így kijelenthetjük: a várható értékek egyezésére vonatkozó nullhipotézis minden szokásos szignifikanciaszinten elvethet, azaz minden szokásos szignifikanciaszinten kijelenthet, hogy a két csoport (sokaságbeli!) várható értéke között különbség van. (Azaz: a mintában tapasztalt különbség olyan nagy (a minta egyéb jellemzit is figyelembe véve), hogy az már túlmutat a mintavételi ingadozás hatásán, nem hihet, hogy betudható pusztán a mintavételi ingadozás hatásának. Azt kell feltételeznünk, hogy mögötte sokasági hatás (azaz sokaságban is eltér várható érték) van.) Mindezt röviden úgy is megfogalmazhatjuk, hogy a különbség szignifikáns, még más szóval, hogy a két csoport között lényeges különbség van. (Ebben a kontextusban a ,,lényeges statisztikai értelemben szignifikánsat jelent.) Ez a jó pont arra, hogy felhívjuk a figyelmet a különbségre a  most definiált  statisztikai szignifikancia és a  köznapi értelm  klinikai szignifikancia között. E kettt mindig szigorúan különböztessük meg egymástól! A köznapi szóhasználatban a ,,lényeges különbség alatt ugyanis azt értjük, hogy a tárgyterületi (esetünkben: orvosi) skálán mi bír jelentséggel. 1 grammal nagyobb születési tömegnek semmi (klinikai) jelentsége (nem gondol az orvos más klinikai helyzetre, nem rendel más vizsgálat, más kezelést stb.), 500 grammnak nagyon is lehet. A statisztikai szignifikancia viszont teljesen mást mér: azt, hogy mennyire hihet, hogy a különbség betudható a mintavételi ingadozásnak! Adott esetben lehet 500 gramm különbség is (statisztikailag) inszignifikáns (ha nagy a szórás, vagy kicsi a mintanagyság), és lehet 1 gramm különbség is (statisztikailag) szignifikáns (ha kicsi a szórás, vagy nagy a mintanagyság). Biztos ez a döntés? Természetesen nem! Bár a \\(p\\)-érték nagyon alacsony, de mivel nem nulla (soha nem is lehet az), így épp azt mutatja, hogy a döntésünkben mekkora bizonytalanság van  mert van benne. "]]
